All right good afternoon everybody

大家下午好

Welcome!good to see you

欢迎！很高兴见到你们

Hope you all have started your attack labs

希望你们已经开始你们的「attack labs」

Everybody started? be a good time to start I think

每个人都开始了吗？我想现在是个好时候开始了

Anyway I hope you're enjoying it, that's a that's a new one this semester that's

不管怎样，希望你们喜欢，这个实验在本学期是新设计的

I think really interesting and modern and current

我认为这个实验非常有趣，也很新鲜很前卫

Okay today we're going to...

今天我们要讲的是……

Today we're going to talk about something called the memory hierarchy

今天我们要讲的话题是关于存储器层次结构的

Now so far in the class we've thought of memory

至今为止，我们在课上讨论的内存

When we're looking at our assembly language programs

当我们在学习汇编语言程序的时候

We've thought of memory as an array of bytes

我们仅仅是把内存当作一个字节数组

It's the big array of bytes that we can access with that an index called an address

可以用地址作为下标来访问的一个大的字节数组

But in actuality the memory system is a very complex hierarchy of devices

但实际上存储系统是一个非常复杂的设备层次结构

That provides this abstraction of this this large linear array

提供了一个抽象，把内存结构抽象成一个大的线性数组

And so today we're going to look at how memory hierarchies are built

所以，我们今天要探寻存储器层次结构是怎么构建的

And why they're built the way they are

至于为什么要这么做

And what we'll see is that this sort of beautiful confluence of the properties of storage devices

我们可以体会到多种存储设备之间属性的美妙融合

And the properties of programs come together to create this...

以及程序的属性在这当中起到的作用

This beautiful design called a memory hierarchy

这个美妙的设计被称为存储器系统结构

So we're going to quickly kind of do a high-level tour of storage technologies and trends

所以我们现在以一个较高的视角快速地概览存储技术和趋势

We're not going to go into a whole lot of detail

我们现在不会陷入一大堆的细节

The point in looking at these at these the properties of these technologies is that

学习这些技术和属性，关键点是

There are some fundamental properties that determine their performance and their speed

有一些决定着性能和运行速度的，最基本最核心的属性

And determine limits on their performance and speed

也决定了性能和速度的限制

And so I want you to have a,you know, just some high-level idea of what those what those properties are

所以我希望你们首先对这些概念和属性有一个高层次的理解

And then we'll look at a property of programs called locality of reference

然后我们会学习一个程序所具有的属性，叫做程序的局部性

And we'll see how that locality and the properties of storage devices

我们将会看到局部性和存储设备的特性

Come together to suggest this design of memory systems as a hierarchy

合在一起，建议把内存系统设计成一种层次结构

Okay so we'll look at memories first

好的，下面我们首先来看一下内存的概念

Now the the workhorse memory is called a random access memory or RAM

现在大多数人所熟悉的内存其实叫做随机访问存储器（RAM）

it's traditionally packaged up as a chip

它一般都是被打包成芯片

And then you put multiple chips together to form your main memory

然后你有很多个这样的芯片，组合起来就成为你的主存

And there's a basic storage unit called a cell which where each cell stores one bit

最基本的存储单位称为单元，一个单元存储一个 bit

Okay now there's a RAM comes in two varieties

RAM 可以分为两种

There's a SRAM and DRAM and they're distinguished by the way that those cells are implemented

一种是 SRAM 另一种是 DRAM，它们之间是根据存储单元实现方式来区分的

So in

所以...

and SRAM requires it's more complex than DRAM it requires like 4,6 transistors per bit whereas DRAM only requires a one transistor

例如，DRAM 只需要一个晶体管去存储一比特，而 SRAM 更复杂，需要约 4 或 6 个晶体管

Okay so you'll see that SRAM are going to be more expensive lots more expensive

所以 SRAM 的成本会高得多

Because they're more complex each cell is more complex

因为 SRAM 的每一个存储单元都比 DRAM 复杂的多

But they're also much faster like ten order magnitude faster than DRAMs

但 SRAM 的速度也比 DRAM 快一个数量级

And they have there's some other properties too like

他俩也有一些其他的性质

SRAM constantly,a DRAM constantly needs to be refreshed

DRAM 是需要被刷新的

If you don't hit it with a voltage

如果你没有用一定的电​​压去充电

It loses the charge whereas DRAM while it needs to be plugged in

它就会丢失电荷，丢失所保存的信息，所以 DRAM 是需要插着电用的

And and have an electric charge it doesn't need to be refreshed

如果有在充电，那就不需要被刷新

SRAM is a lot more reliable than DRAM so it

SRAM 就比 DRAM 更加地可靠

There's less need for error detection and correction

所以不太需要进行错误检测和纠正

And there and so because of this difference right the SRAMs are costlier smaller and faster than DRAMs

因此。SRAM 比 DRAM 更小，速度更快

We find SRAMs being used in these small fast memories on chip called cache memories

所以，我们将 SRAM 用于那些内存容量小但速度非常快的芯片中，叫做高速缓存

And we're going to learn all about those on Thursday

我们将在星期四学习这些有关高速缓存的话题

And then DRAM is the workhorse used in main memories and the frame buffers associated with graphics cards

相比之下，DRAM 被广泛运用于主存，以及图形显卡中的帧缓存中

Now DRAM and SRAM are volatile in the sense that if they're powered off they lose all the information right so this is why

现在 DRAM 和 SRAM 都是易失的，意味着如果断电，就会丢失它们所保存的信息

When you turn your computer off you have to you lose everything in your memory

这也是为什么当你关掉电脑后，你会丢掉所有内存中的东西

And you have to when you turn it back on you have to sort of reload everything from your disk

再把电脑打开后，你需要从硬盘中重新加载所有东西

There's a different another kind of memory called a nonvolatile memory which retains its information when it's powered off

有另一种存储器，称为非易失性存储器，即使断电的情况下也可以保存其中的内容

And there's a whole bunch of these things that so called up read-only memory

很多这些东西被称为只读内存

So the generic name for these nonvolatile memories is read only memories ROM

因此，这些非易失性存储器的通用名称是只读存储器（ROM）

And there's a whole bunch of different kinds sort of going back in time the original read only memories were ROMs

在以前，很多最初的不同类型的 ROM

And they can only be programmed once when the chip was produced

它们只可以在其芯片生产期间被硬编码一次

And then over time gradually over period of like 20 or 30 years

然后可以用 20 或 30 年的时间

There were improvements in the way that ROMs could be programmed and in how they were erased

现在，ROM 的编程方式和删除方式都有所改进

So they could be reprogrammed

它们可以被重新编码

The what we have today the the modern form of read only memories is called flash memory

今天我们拥有的现代形式的只读内存被称为闪存

Which provides the capability of erasing you can erase just chunks of the the flash memory called blocks

它提供了擦除功能，你可以删除闪存上面的存储块

And then the downside is that these things wear out after about a hundred thousand erasers

缺点是闪存约在十万次擦除之后就会磨损了

Okay so you can erase and reprogram a hundred thousand times and then it's your bricked

你可以擦除然后重新编码约十万次后它就会损坏

Now that these nonvolatile memories are show up in with

非易失性存储器可以在固件和软件中使用

So called firmware which is software

非易失性存储器可以在固件和软件中使用

That's that's programmed into a ROM

可以对 ROM 进行硬编码

And you see those in the BIOS of computers so when you power on your computer

当你开启电脑时会调用的 BIOS

The very first instructions that execute are stored in a ROM right

以及开机后执行的最初的指令，都存储在 ROM 中

If you're wondered like where do those things come from so they're stored in ROM

如果你想知道这些东西来自哪里，那么它们就存储在 ROM 中

And then there's a boot process where gradually more and more information is

然后有一个 boot 引导程序

And instructions are loaded into memory

越来越多的信息和指令都被装载到内存中

You know IO. IO devices have little computers in them call controllers

你们知道 I/O 吧？I/O 设备中也有小型的计算机，称为控制器

These controllers consist of instructions and data that are that are stored in ROMs

控制器由存储在 ROM 中的指令和数据组成

And you see them all over the place in these solid state disks

你还可以在这些固态硬盘（SSD）中看到它们

That to the system look like a rotating disk

系统仍然把它们当作旋转的硬盘

But they're built of flash memories

但它们实际上是由闪存构成的

Okay and these are you see these in thumb drives, smart phones, tablets and laptops

就是你在 U 盘、智能手机、平板电脑和笔记本电脑中能看到的那些

And they're even starting to show up in servers now

现在，它们甚至也在服务器中被使用

So the memories are connected to the CPU using sort of wires that are collectively called buses

主存是通过一些电子线路连接到 CPU 的，这被称为主线（bus）

Okay so data flows across the wires back and forth from the,we have the CPU chip

数据流就可以从内存和 CPU 芯片之间来回传输

And it consists of register file these are the general-purpose registers %rax, %rdi and so on

CPU 芯片中有一些寄存器，例如这些是通用寄存器：％rax，％rdi 等等

And there's an arithmetic logic unit that reads and writes data from the register files

有一个算术逻辑单元会从寄存器文件读写数据

And then manipulates that data in some way by doing some kind of arithmetic operation or some logical operation

然后对数据进行一定的算术运算和逻辑运算

And if instructions need to access memory

如果指令需要访存

So if there's you're doing a move,a move instruction that reads or writes to memory

所以你需要执行一个移动指令 (mov) ，移动指令会读写内存

Then that's handled by a bus interface which is connected to a what we'll call a system bus

然后由总线接口处理，该接口连接与另一个接口相连接，我们称之为系统总线

And then that's connected to an I/O bridge and this

然后它连接到 I/O 桥

This is another collection of chips,Intel calls this what I'm calling the I/O bridge,they call the chipset

这是另一个芯片集合，我所称的 I/O 桥，英特尔称之为芯片组

Okay but it's it's a collection of chips separate from the process the CPU chip

是与 CPU 芯片区分开来一个芯片集合

And then the I/O bridge is connected to another bus called the memory bus which connects the main memory

然后 I/O 桥连接到另一条主线，叫做存储器主线，连接 I/O 桥与主存

Okay now this is kind of an abstraction I don't want you to take this too literally

好的，这只是一种抽象，我不希望你们太在字面意义上较真

But it gives you the idea of how information flows in the system

但它让你了解信息如何在系统中流动

Okay modern modern systems use proprietary bus designs and they're very arcane and increasingly complex

现代系统使用的专有总线设计，它们非常神秘且越来越复杂

So we're just going to use a fairly simple abstraction for these bus architectures

所以我们才在这里使用一个非常简易的总线系统抽象

Now when is,now suppose you do a load operation like movq

现在，假设你执行了一个装载操作，像是执行 movq 指令

The eight bytes at address a into %rax

将 A 地址处的 8 个字节加载到寄存器 %rax

Okay so we call that a load because we're loading from the point of view of the CPU

之所以我们称之为加载（load），是从 CPU 的角度出发来考虑的

We're loading data into the CPU

我们是加载数据到 CPU 中

But we're loading and we're loading data from memory into the CPU

但实际上我们是从主存中加载数据到 CPU 的

So when the CPU executes movq instruction like this

所以当 CPU 执行 movq 指令时，是像这样进行的

It first places the address of A on the memory bus

首先，CPU 将 A 的地址放到存储器主线上

And then the main memory senses that address and it reads the contents the eight bytes at address A

然后主存储器感知到这个信号后，读取这个地址 A 处 8 字节的内容

So it retrieves the word 8 byte word from address a and places it back on the bus

也就是它会从该地址取得一个 8 字节的字的内容然后将其放回总线上

The those bits travel through the I/O bridge to the bus interface

这些比特会在 I/O 桥上传递回总线接口

And then the CPU reads the the word x from the data word x from the bus and in composition to register %rax

然后 CPU 从总线数据中读取这个字 x，然后放到寄存器 %rax 中

Okay so it's now writing is is similar again

然后写入是一个相似的过程

So here we're doing a move instruction movq from %rax into address A main memory

这里我们执行一个指令 movq，将寄存器 %rax 的内容写入主存中地址为 A 的位置

Okay so the the CPU starts as before by placing the address a on the bus

像以前一样，起初，CPU 也将地址写到总线上

Main memory reads that address and then it waits for the data to arrive on the bus

主存读取这个地址，然后等待数据到达总线

So the CPU then places the contents of %rax on the bus

然后 CPU 将寄存器 %rax 的内容放到总线上

Those contents travel across to main memory

这些数据传输到主存

Which then reads the reads that word from the bus and stores it at address A

主存读取这些数据，将其存放到地址 A 处

Ok so that the point of all this is that operations that occur

好，其中的关键点在于其中的操作

You know reads and writes of registers

也就是寄存器的读写

Because the register file is very close to the ALU, these happen in on the order of a few cycles

因为寄存器文件是很接近算术逻辑单元的，这一切都发生在大约几个 CPU 周期内

Ok register,the register very close to the ALU

寄存器文件很接近算术逻辑单元

So those operations are very happened very quickly

所以这些操作的速度都很快

Whereas memories actually this is a set of chips that are very far away relatively speaking from the CPU

然而，内存实际上是非常远离 CPU 的一些芯片组

And there's a lot going on in when if you have to read or write memory there's

当你需要读写内存时，那么会发生很多事情

It you have to do multiple operations on the bus,data has to travel propagate across that bus all this stuff takes time

你必须在总线上做多个操作，数据必须通过该总线传播，所有这些操作都需要时间

So memory operations reads and writes are typically

所以，对于内存的读写，典型地都需要大约 50 或 100 纳秒

You know maybe 50 nanoseconds 100 nanoseconds whereas operations that occur between registers are sub nanosecond

而寄存器之间的一些操作所需时间甚至不到 1 纳秒

On the order of so you're talking about a one to two orders of magnitude difference

所以它们之间大约差了两个数量级

If you have to go off chip to to retrieve something from memory

如果你需要离开 CPU 芯片，到主存那儿去取一些东西

Ok so that's the first sort of big takeaway item about memory systems

好，这就是内存系统引入的第一个损耗

Now another popular storage technology is rotating disks

现在还有另一项广泛应用的存储技术就是硬盘

And I don't know if you've ever torn one apart they're kind of interesting there's a series of platters

不知道你们有没有拆过硬盘，蛮有趣的，硬盘其实是一系列的盘片

Each platter is coated with a magnetic material

每个盘片都涂有磁性材料

And then and then bits ones and zeros are encoded in that magnetic material

然后在该磁性材料中编码 1 和 0 的二进制位

And then there's this arm that can it's it's hinged right here

有一个部件叫做传动臂，铰接在这里

And then it can it floats over the platter so it floats on a thin layer of air over the platter

然后它可以漂浮在盘片上，它漂浮在盘片上方的薄薄一层空气中

And there's a read/write head at the very end that can sense the changes in the magnetic field that encode the bits

在最末端有一个读/写头，可以感知编码位的磁场变化

Okay so these platters are spinning around like counterclockwise like this, this arm can go back and forth

这些盘片像逆时针一样旋转，这样磁臂可以前后移动

So there's a lot of mechanical gear so this is all mechanical

所以有很多齿轮等机械装置，这些都是机械设备

So the mechanical nature of a rotating disc

所以旋转磁盘的机械性质

Means it's going to be slower right then DRAMs and SRAMs

意味着它会比 DRAM 和 SRAM 慢

And there's also electronics like it's like a little computer in firmware

而且它还有电子设备，就像固件中的一台小电脑一样

That that actually controls the operation of this drive that controls how this arm goes back and forth

控制了驱动器的操作，该驱动器控制磁臂如何来回移动

And and and controls how the data is read off of the the read/write head

并且控制如何从读/写头读取数据

So just in a little more detail we can think of these disks consists of platters

我们来讨论一些细节，我们可以认为磁盘是由盘片组成的

Each platter has two surfaces the top and a bottom

一个盘片有两个表面，上面和下面

And then each surface consists of these trace, these are concentric rings  called tracks

每一个表面都包含一系列的同心圆，称之为磁道

And then each track consists of us it consists of sectors which contain the data

每一个磁道包含很多个扇区，扇区存储着数据

So typically 512,512 bits, oh I'm sorry bytes

典型地，一个扇区存储 512 个 bit...... 不好意思，是 512 个字节

And in the set of these tracks are separated by gaps

在这些「磁道」之间有一些空隙（注：这里口误，应为扇区之间）

That these gaps like right here that don't contain data

这些空隙是不保存数据的

Now platters are aligned on top of each other on the spindle

盘片在主轴上是彼此对齐的

And so tracks that are aligned on the different surfaces

因此，在不同表面上，轨道也是对齐的

Such as this track here on those the collection of those

比如这条轨道，这些轨道的集合

Tracks form what we call a cylinder okay because it has a cylindrical shape

这些轨道的集合，我们称之为一个柱面，因为它形成一个圆柱形

Now the capacity of disks is that the number of bits that can be stored

磁盘的容量就是它可以存储的位数

And vendors kind of they all dis vendors use they quote the capacity in gigabytes

所有供应商都以千兆字节（GB）为单位来表达磁盘容量

But where a gigabyte is 10^9 bytes right instead of 2^20,okay like like you would expect

这里的 1GB 是 10^9 字节而不是你所想的 2^20 字节

So what...I'm not sure why they do this

我也不确定他们为什么这样做......

But it allows by by quoting their capacity and gigabytes in 10^9 bytes

不过，允许以 10^9 字节作为容量的单位

It's a bigger number right

这是一个更大的数字对吧

So it looks better it looks like there's more information

所以看起来好像可以存储更多的信息

It's a little I don't really know why they do it but I think that's why it is

我不知道他们为什么这样做，但我认为可能原因就是那样的

And it's one of those little bit annoying things that we just have to just  know about and get used to

有点烦人，所以我们需要了解，然后习惯这个设定

Now the capacity is determined by 2 independent technology factors

磁盘的容量是由两个独立的因素所决定的

One is the recording density so that's how many bits can you pack into a single sector

第一是记录密度，决定单独一个扇区可以存储多少比特

Or ... or at least a portion of a track

或者至少是一个磁道的一部分

And then the track density which is sort of how close can you put those tracks together

然后是磁道密度，指可以将相邻的磁道放置得多临近

And then the product of those two is what's called the areal density and that determines the overall capacity of the disc

这两者的乘积，称为面密度，决定了整个磁盘的存储容量

So the higher the areal capacity the more bits you can squeeze on to that onto that surface

面密度越高，你就在一个磁面上可以存储越多的比特

Now in the old days when aerial densities were fairly low

在以前，磁盘的面密度相当低

Each each track on the surface would have the same number of sectors

磁面上每一个磁道所包含的扇区数量是相等的

Okay so there was a constant number of sectors per track

每一个磁道所包含的扇区数是一个常数

So now what happens as you as your tracks go from the

现在会有一种情况

You know near the whole by the spindle as they go as they move outward

磁道有比较靠近中心也有较为边缘的

Right if you have the same number of sectors with the same bit density

如果磁道是由相同比特密度的扇区组成

That the gaps between sectors are going to get bigger and bigger as you go out

那么越往外，扇区间的间隙会越变越大

And you're going to be wasting more and more of your space

你将会浪费越来越多的磁面上的空间

So at when aerial densities were fairly low this was okay

不过如果面密度比较低的时候这还是可以接受的

But after a while it just became not okay to waste that much room

但随着技术发展，浪费空间就不太能被接受了

So what modern systems do is they partition the tracks into these

现代的系统为此所做的改进是

So called rook recording zones

将磁道划分为所谓的记录区

Where each recording zone such as this right here

这里的每一个记录区，如图所示

Each recording zone has a constant number of sectors

每一个记录区包含相同数量的扇区

So each track in a recording zone has the same number of sectors

所以一个记录区里的每一条磁道都有相同数量的扇区

And of course as you move outward if you move outward in the recording zone

当然，对于越靠外的记录区

You're going to have bigger and bigger gaps

将扇区之间的空隙会越来越大

But then you start a new recording zone

但是在这里看这个新的记录区

That will have more sectors per track and then within that

它的每一条磁道里会有更多的扇区

So you can see in this outer in this outer zone you have more you have more sectors

你可以发现，在靠外的磁道，会比靠内的磁道有着更多的扇区

Than you do on this inner zone

你可以发现，在靠外的磁道，会比靠内的磁道有着更多的扇区

Okay so that's a way to kind of deal with that sort of that growth in the gaps to keep it from getting too large

这就是处理扇区之间的间隙变得过大的方法

And so because we don't really have the number of sectors per track isn't constant

因为采用了此技术，每一条磁道所包含的扇区数不再是一个常数

We'll use an average, the average sectors per track across

于是我们使用平均值，也就是每条磁道平均包含的扇区数

all recording zones when we do serve our capacity estimates

用所有记录区的平均每条磁道扇区数来估计整个磁盘的容量

Okay so you can imagine the formula for computing the disk capacity is fairly straightforward

好的，你可以想象计算磁盘容量的公式是相当简单的

It's the number of bytes per sector

它是每个扇区的字节数

Times the average number of sectors per track

乘以每个磁道上的平均扇区数

Times the average number of tracks per surface times the number of surfaces per platter

再乘以每个盘面的平均磁道数，再乘以一个盘片的盘面数

Times the number of platters per disk okay

最后在乘以磁盘中盘片的数量

Now let's look at how just work

现在让我们来看看它是如何工作的

So these these surfaces are spinning at a fixed rotational rate

这些表面都以一个固定的频率在旋转

Now a typical rate may be 7200 rpm s is a fairly common rotational rate

现在典型的速率可能是 7200 转/分钟，这是相当常见的转速

So the disc is spinning around you can see this pretty proud of that

如你所见磁盘是这样旋转的，我还（对这个PPT）挺自豪的

So it's spinning around counter clockwise and then the arm

像这样逆时针旋转，然后，磁臂

Moves radially here we go

磁臂沿着半径轴前后移动

The arm moves radially and it can go over any of the tracks

磁臂沿着半径轴前后移动，可以定位到任何一个磁道上

Okay all right that's enough

好的这部分讲到这里

Okay now when you have multiple platters

好，现在考虑多个盘片的情况

Each one of these there's actually multiple arms and there's a read/write head on each surface

每一个盘片都有磁臂，实际上都有多个臂，每个表面上都有一个读/写头

So if the platters has two - if - if each side of the platter

所以一个盘片有两个（磁头），上面下面各一个

Is coated with this magnetic material then

涂上这种磁性材料

You'll have you have a read/write head on each side

会在每一侧都有一个读/写头

And then these are all connected they kind of move together

然后这些都是连接在一起的，一起移动

Now originally these these read/write heads would be they were rigid

现在，原始的这种读/写头将是很死板的

Right because the densities tracked densities weren't that high

因为那时候的磁道密度没有那么高

So they could they could just sort of likes and even though the tracks didn't align perfectly

所以即使磁道没有很好地对齐

They could just sort of they could they could still cover

它们还是可以全部覆盖

The read/write heads could still cover the tracks with these fixed arms

读/写磁头仍然可以用这种固定的磁臂覆盖所有磁道

But nowadays that the densities are so high

但现如今，磁道密度如此之高

That they actually the controller can actually move the read/write heads a little bit

实际上控制器实际上可以移动读/写头一点点

So that it matches up with that all of the tracks on all of the surfaces

这样它就匹配了所有表面上的所有轨道

Okay so let's look at how this works how we read data

好的，一起来看一下我们读取数据的方式

So we have our

首先，我们有

This is our this is our arm and the tip of the arrow is the read/write head

这是我们的这是我们的磁臂，箭头的尖端是读/写头

And it's positioned and the platter is rotating counterclockwise

并且它被定位并且盘片逆时针旋转

And its position just ready to read the blue sector

读写头当前的位置正好可以读这个蓝色的扇区

So it as the blue sector spins underneath the read/write head

当蓝色扇区在读/写头下旋转

It senses those bits and sends them up to the controller which passes them back up to the  the CPU

它会检测这些比特，并将它们发送到控制器，控制器将它们传递回CPU

And now the CPU is requested that the disk

现在，CPU请求磁盘

It's requested the red data from the red sector

它要求磁盘读写红色扇区的数据

So we have to take the controller takes that read/write head

所以，控制器需要操控读/写头

Moves it back to reds track

先将其移回红色扇区所在的磁道

And then waits for it to spin around and

然后等待磁盘旋转

And to the to the read/write head

等到该扇区旋转到读写头的下方

And then it reads that that red that red sector

然后读取红色扇区中的数据

Okay so when we first so there's really three components going on here that determine

所以这里一共有三个因素

How long it takes to read one of these sectors

决定着阅读其中一个扇区需要多长时间

The when we move the head that's called a seek

移动磁头的时间称为寻道时间

When we waited for the red track to sort of rotate around

我们等待磁盘旋转，等红色扇区旋转到读写头下方

That's called the rotational latency so how often long it takes

这部分称为旋转延迟，它通常有多长时间呢

On average it will be half of the half of the time

平均情况下就是磁盘旋转一整圈所花费的时间的一半

It takes for the entire to circle all the way around

平均情况下就是磁盘旋转一整圈所花费的时间的一半

And then there's the data transfer which is

最后一个因素是传送时间，是指

Sort of how long it takes for that

是指该轨道在读/写头下通过的时间

For that track to pass under the read/write head

是指该轨道在读/写头下通过的时间

Now the reason the reason it's important to know this is that

知道这些的重要原因是

These three components you add them together and that's the that's what your average

这三个因素，将它们加在一起，这就是你的平均值

X time it takes to access data

磁盘访问数据的平均时间

That time is dominated by the seek time

磁盘访问数据的时间主要是寻道时间

So seek times are measured in milliseconds right so we're moving this head there's

所以寻找时间是以毫秒为单位测量的。寻道就是把磁头移到那里

This there's a servo that has to fire up and there's actual mechanical motion

这是一个伺服系统，是实际的机械运动

And that that takes time

这就要花时间

And it's on the order of three to nine milliseconds and this has been true for decades

它大约在 3 到 9 毫秒之间，这已经存在了几十年

Right so this this value is not changing right

这个值是改不了的

There's just sort of fundamental mechanical limits

这是一种基本的机械限制

That make it very difficult to to decrease this this value

这使得降低这个值非常困难

Now the rotational latency

下面谈谈旋转延迟

The time that it takes to spin around will we'll call that the t average rotation

旋转所需的时间我们称之为 Tavg rotation（平均旋转时间）

And then the time it takes to read the the bits will call t average transfer

然后，磁头读取这些比特所需的时间称为 Tavg transfer（平均传输时间）

Okay so we have t average seek which is this seek time, rotational latency and transfer time

好的，所以我们的搜索时间包含三个部分，即寻道时间、旋转延迟和传输时间

And now if we just take some typical numbers   and plug those in

现在，我们取一些真正的数字来做一些运算

You see that our seek time is on the order of milliseconds

你看，我们的寻道时间是毫秒级

The rotational rate is also on the order of milliseconds right

旋转延迟也是毫秒级

So there's there's also mechanical limits and how fast you can you can spin these around

有机械限制，限制了你可以用多快的速度旋转它们

The access time and the transfer time  is very small

传输时间是非常短的

So it's orders of magnitude smaller because you just have to read a few that the bits that are in one sector

所以它的数量级要小一些，因为你只需要读扇区中的一些位

Okay so if you look you can see that the total access time is dominated by seek  and rotational latency

好的，你可以看到总访问时间主要是寻道时间和旋转延迟

So you know a good rule of thumb just for sort of estimating how long it takes to read from a disk

所以这儿有一个好的经验法则，用于估计从磁盘读取数据所需的时间

It is just take twice the seek the seek time and you'll be pretty close

就是两倍的寻道时间，就很精准了

And basically the transfer time is you get that for free

基本上传输时间可以忽略不计的

Now here's the here's the important thing to know about disks

现在，这里要讲一些有关于磁盘的重要信息

We SRAM access times about four nanoseconds to get a double word

访问 SRAM 取得一个 double 类型的双字，时间大约为 4 纳秒

Dram is about 60 nanoseconds

在 DRAM 上大约是 60 纳秒

So DRAM is about an order of magnitude slower than SRAM

所以 DRAM 比 SRAM 慢一个数量级

But disk is 40,000 times slower than SRAM

但是磁盘比 SRAM 慢 40,000 倍

So that's 4,000 orders of magnitude difference

这就是 4,000 倍的差异

That's huge and it's it's 250 times orders of magnitude slower than DRAMs

这个时间差是非常巨大的，它比 DRAM 慢 250 倍

So the there's a big gap between DRAM and SRAM

所以 DRAM 和 SRAM 之间存在很大差距

And there's an even bigger gap between disk and other memory types

磁盘和其他内存类型之间存在更大的差距

Now modern disks present a much simpler view

现在，现代磁盘呈现出更简单的视图

Than so we then this track cylinder sector geometry

我们这里学到的磁道、柱面、扇区等几何描述

So modern modern disk controllers actually present

实际上现代磁盘控制器

To the CPU they present the disk as a sequence of logical blocks

是将磁盘作为一系列逻辑块提供给 CPU

Where each block is is a multiple of a sector size

每个块是扇区大小的整数倍

So this in simplest case a block is just a logical block is one sector

所以在最简单的情况下，块只是一个逻辑块就是一个扇区

And then blocks are numbered starting at zero

块从零开始编号

And they just go all the way up to some to some large number

块号是一系列增长的数字

And then the the disk controller keeps the mapping maintains the mapping between logical blocks

然后磁盘控制器保持映射保持物理扇区和逻辑块之间的映射

And the actual physical sectors

然后磁盘控制器保持映射保持物理扇区和逻辑块之间的映射

So as in the old saying is you know most interesting ideas in computer science are involve some form of indirection

计算机科学中古老的有趣的智慧就是涉及某种形式的间接

So this is a level of indirection

所以这是一个间接层面

That provides you know this mapping between logical blocks and physical blocks

让你了解逻辑块和物理块之间的映射

So it allows disk controllers to take some cylinders and reserve them as spare cylinders

它允许磁盘控制器将一些柱面保留为备用柱面

That aren't mapped it in logical blocks

这些柱面没有被映射为逻辑块

And then if there's if one of the sectors goes bad in a cylinder

如果有个柱面的一个扇区坏了

That the disk controller can just copy the data over to a spare cylinder and then just keep going right

磁盘控制器可以将数据复制到备用柱面，然后磁盘就可以继续正常工作

So this is why your formatted capacity is less than sort of the if you know if you counted the number of actual cylinders on the disk

这就是为什么磁盘的“格式容量”会比实际容量要小，如果你去数实际的柱面数的话

Your formatted capacity is less than the maximum capacity

“格式容量”会比实际容量要小

Because some of those cylinders are being reserved for failures

因为其中一些柱面是为故障处理而预留的

Now devices like disks are connected to the to the CPU and the memory

现在，像磁盘这样的设备连接到 CPU 和内存

Via the I/O bridge over another kind of bus called an I/O bus

通过 I/O 桥，通过另一种称为 I/O 总线的总线

This what I'm showing you now is actually not representative of modern systems

我现在向你展示的内容实际上并不代表现代系统就是这么简单的

It's representative of what was called the pci bus about five years ago

它代表了大约五年前所谓的 PCI 总线

Modern buses now are the pci bus is a broadcast bus meaning it's just a single set of wires

现代总线是……PCI 总线是广播总线，这意味着它只是单一线路

So if any device us changes the values on those wires

因此，如果这根总线上的任何设备更改了某个值

Every device on that bus can see those values

该总线上的每个设备都可以看到这些值

Okay that's called a broadcast bus and it's a simplest kind of way to hook things together

好的，它被称为广播总线，它是将事物连接在一起的最简单的方式

Modern systems use a bus structure called pci express

现代系统使用称为 PCI Express 的总线结构

Which although it has the word pci and it's completely different it's point-to-point

虽然它有 PCI 这个词，但它是完全不同的，它是点对点的

So devices are connected by a set of point-to-point connections

因此，设备通过一组点对点连接进行连接

Arbitrated by a-- by some kind of a switch

通过某种开关仲裁

And we won't go into it it's the same idea it it's a much more efficient design

我们不会深入探究其细节，它是一个更有效的设计

It's much faster and but it provides the same capability mainly it just attaches up

它更快，但它提供相同的功能，

It allows you to attach all of your devices to your to your CPU

它允许你将所有设备连接到 CPU

So just think of this bus as this sort of a single set of wires

因此，只需将此总线视为一组电子线路即可

Where each wire carries a bit

每根电线都带有一个比特的信息

And every device attached to it can see all the values of all the wires

并且连接在总线上的每个设备都可以看到所有电线上的所有值

And so it there's some devices that are just built it directly into the motherboard and they attach to the bus like

有一些设备是直接焊接在主板上的，直接连接到总线上

You know disks have just plugged directly into sockets on a motherboard

磁盘是直接插入主板上的插槽

And you know your graphics adapter and the USB controller

还有诸如图形适配器和 USB 控制器

And then the system presents an interface

然后系统提供一个接口

So you can plug mouse things like mice and keyboards into the USB controller

因此，你可以将鼠标和键盘等插入 USB 控制器

And then there's expansion slots that allow you that are

然后还有扩展插槽

Connect to the wires in the in the bus that allow you to add other devices right

允许你添加其他设备，将其连接到总线上

Maybe network you know if you want to put a network adapter there

例如你想在那里放一个网络适配器

Now what happens when we want to read a disk sector

当我们想要读取磁盘扇区时会发生什么

Well the CPU initiates this read by writing a triple

那么 CPU 通过编写三元组来启动此读取行为

So it writes three different values it writes a command like say read

所以它写了三个不同的值。首先是写了个指令，比如说 read

It writes a logical block number

它还写入一个逻辑块号

So I want to read a logical block number

是我想读取的那个逻辑块的块号

And I want to place the contents of that logical block at a certain address in memory

然后我想将该逻辑块的内容放在内存中的某个地址

Okay so it's a command, logical block number, in a memory address

好的，三要素就是指令、逻辑块号和内存地址

The disk controller reads the whatever sector corresponds to that logical block

磁盘控制器读取与该逻辑块对应的任何扇区

So we'll assume that logical blocks are consists of one sector

所以我们假设一个逻辑块由一个扇区组成

And then it does this interesting thing it copies it takes control of the bus

然后它做了这个有趣的事情，它取得总线的控制权

And it copies the data this is the disk controller now

它现在复制数据，这是磁盘控制器

Copies the data across the I/O bus through the I/O bridge and directly to main memory without ever notifying the CPU

通过 I/O 桥将数据复制到 I/O 总线，直接复制到主存储器，而无需通知 CPU

So the CPU is completely oblivious to the fact that this transfer is going on

所以 CPU 完全忘记了这种传输正在进行的事实

And then once it's once its transfer the data to main memory

然后，一旦它将数据传输到主存储器

Then it notifies the CPU using this mechanism called an interrupt

然后它使用这种称为中断的机制来通知 CPU

So it actually asserts a pin on the the actual CPU chip itself

所以它实际上 CPU 芯片本身上用了一个引脚

So it it changes the value of that pin from 0 to 1

它将该引脚的值从 0 更改为 1

And that trigger is an interrupt and which notifies the CPU that sector has been copy

该触发器是一个中断，它通知 CPU，该扇区已被复制

Ok so then the CPU if there's some program somewhere waiting for that data to be read into memory

好的，对于 CPU 来说，现在某处有某个程序正在等待，将数据读入内存

So now the CPU can execute that program and deal with that memory

所以现在 CPU 可以执行该程序并处理该内存

So what this what this mechanism allows

那么这个机制有什么好处？

And the reason they do this is because disks are just so god-awful slow

他们这样做的原因是因为从磁盘读取数据实在是太慢了

The within 10 milliseconds a system could be executing millions and millions of instructions

在 10 毫秒内，系统可以执行数百万条指令

The CPU could be executing millions and millions of instructions

CPU可能正在执行数百万条指令

It will be a terrible waste if the CPU waited for that data to come off the disk

如果要让 CPU 停下来，等待从磁盘上读取数据完毕，那将是一个可怕的浪费

So what it does is it it issues this request to the disk controller

这个机制做的事情就是它将此请求发送给磁盘控制器

And then while that well that really slow laborious process is going on

然后，虽然那个非常缓慢的磁盘读取过程正在进行

The CPU can be executing other instructions and doing other useful work

但 CPU 可以同时执行其他指令，执行其他有用的工作

So this is really essential to just sort of getting reasonable performance

所以这对于获得合理的性能非常重要

And from keeping this really slow disk system from slowing the system down

防止这个非常慢的磁盘系统减慢整个系统速度

Now there's another interesting hype kind of disk called a solid-state disk

现在有另一个有趣的很火热的类型的磁盘称为固态磁盘

Which is kind of halfway between rotating and rotating discs  and DRAM memories

大概是旋转磁盘与 DRAM 存储器的中间点

In a solid-state disk to the to the CPU

在 CPU 看来，一个固态磁盘

It looks exactly like a rotating disk it has the same socket plug

它看起来与旋转磁盘完全相同，它具有相同的接口

It has the same physical interface that has the same packaging

它具有相同的物理接口，具有相同的包装

It looks like a rotating disk

在 CPU 看来就好像是一个旋转磁盘

But instead of having all these mechanical parts it's actually built entirely out of flash memory

但它没有所有这些机械部件，而是完全由闪存构建

And firmware that acts as the the controller

和充当控制器的固件

So inside of a solid-state disk there's a firmware a set of firmware called the flash translation layer

因此，在固态磁盘内部有一组固件，称为闪存翻译层

Which serves the purpose as the same purpose as the disk controller does in a rotating disk

其作用与旋转磁盘的磁盘控制器相同

And then the memory itself the read

然后内存本身......

Data can be read and written from the flash memory in units of pages

可以以页为单位从闪存读取和写入数据

Which depending on the technology can be 512 kbytes to 4 k bytes

页的大小取决于技术的不同，可以是 512 千字节到 4 千字节

And then a sequence of pages forms a block

然后一系列的页形成一个块

Now these blocks are different from the logical blocks that the CPU does

这里提到的块与 CPU 所认为的逻辑块是不同的

So it's kind of an unfortunate overlap of terms

所以这是一个不幸的术语重叠

But the the trick is or the I guess the limitation is that data is written in units of pages

但这里有个诀窍是，我猜这里的限制是在固态硬盘中，数据是以页为单位写入的

But a page can only be written after the entire block has been erased

一个页只能在所属的整个块都被擦除之后，才能写这一页

Okay so that's that seems kind of weird but that's that's the way it works

好的，这似乎有点奇怪，但这就是它的工作方式

So what that means is if you want to write

那么这意味着你想要对固态硬盘进行写入

If you want to write to a page you have to find a block somewhere that's been erased

如果你想写一个页，你必须找到一个被擦除的块

You have to copy all of the other pages in your target block over to that new block and then you can do the right

你必须将目标块中的所有其他页面复制到该新块，才能正确执行

Okay so you can see that write now become fairly complex operation. Reads you can read anything

好的，你可以看到现在写操作变得相当复杂。读操作没改变，你还是可以读任何东西

And then like all flash a so it's kind of an efficient right because you're writing one page

然后像所有闪存一样，这是一种有效的机制，因为，你正在写一页

But to do that you have to sort of copy all the other pages in it block and you have to erase the whole

但要做到这一点，你必须复制该块中的其他所有页面，你必须擦除整体

And then when you finish then you erase this block so it can be used for for other writes yes

然后当你完成后，你擦除这个块，以便它可以用于其他写入

So eventually after a hundred thousand repeated writes these we're out

所以最终在经过十万次重复写入后，这个块就会磨损

Now the flash translation layer in modern systems

现代系统的闪存翻译层

Do all kinds of fancy proprietary algorithms to sort of extend the life. They use caching

实现了各种花里胡哨的专有算法，以延长 SSD 的使用生命，例如缓存技术

And and various tricks to extend the life of these SSD

并且还有各种技巧来延长这些 SSD 的使用寿命

So in practice it's not really a problem, which I'll show you in a second

所以在实践中，这不是一个大问题。我接下来就会展示

So the performance characteristics of SSDs

下面介绍 SSD 的性能特点

Now you can think of a typical hard drive you might be able to get

现在你可以想到一个典型的硬盘，它的读写速度大概

You know I mean what if when I measure them when I measure my drives

你知道我的意思，是指去测量磁盘驱动器（的读写速度）

I maybe forty, fifty megabytes per second that would be a typical rate

可能是每秒 40 或 50 MB，这是一个典型的速度

Okay these SSDs are 10 times faster than that

而 SSD 的速度要快 10 倍

So for sequential reads you can get about 550 megabytes

因此对于顺序读取，你可以获得大约 550MB/s 的速度

Sequential writes are a little bit slower

顺序写入有点慢

Random access whether you're reading or writing is a little bit slower than sequential access

如果是随机访问，无论是读或写都比顺序访问慢一点

And as we'll see this is that this is fairly common

而且我们会看到这是相当普遍的

It's it's in memory systems it's almost always better to do things sequentially  than to jump around

就是在内存系统中，按顺序执行操作几乎总是比在内存中跳来跳去更好

And erasing random writes are slower because erase erasing takes about a millisecond right

随机写入速度较慢，是因为擦除的存在，擦除需要大约一毫秒的时间

So now we're back up to that that millisecond range which is which is slow

所以现在我们又回到那个毫秒级的范围，这就很慢了

And as I mentioned yet if you modify one page after all the other pages in that block have to be copy

正如我所提到的那样，如果你修改某一页，该页所在块中的所有其他页都必须被复制

Now earlier SSDs had a huge gap between random writes and sequential reads

早期的 SSD 在随机写入和顺序读取的速度存在巨大差距

But they because of sort of improvements in the flash translation layer

但因为闪存翻译层的改进，这一差距有所缩小

These are really that that difference right reading and writing it's it's writing is slower

读写操作肯定存在时间差异的，写入更慢，对吧？

But they're doing all kinds of interesting amazing things to get these numbers fairly close

但他们正在做各种有趣的的改进，以使这些数字相当接近

Ok so er... when we have a model of SSDs we really don't need to distinguish anymore that between reads and writes

好吧，当我们有了 SSD 模型，我们真的不需要再区分读和写

Okay so, SSDs because they have no moving parts

因为 SSD 没有移动的部件

They're faster they take less power they're more rugged

所以它们的读写速度非常快，消耗的电能也少，同时也更结实

You know which is why they're good for thumb drives

这就是为什么 SSD 用在 U 盘中是有好处的

And you know ipods and things like that

像是 IPods 和类似的东西

But they have this potential to wear out

但它们有可能磨损

Which could be a problem but in practice it's not

这可能是一个问题，但实际情况也不是大问题

For example, Intel guarantees that you can do 128 petabytes of writes

英特尔保证，在对于他们的产品，在损毁之前，你可以执行 128 PB 的写入

Before your SSD is no longer good

英特尔保证，在对于他们的产品，在损毁之前，你可以执行 128 PB 的写入

So that's a lot of data to write I mean think about how many years it would take to write that much data

那是很大量的数，我的意思是考虑一下要写那么多的数据够你写多少年了

And as of 2015 as of now

截至目前，2015年

They're a lot more expensive per byte than rotating disks

SSD 存储每个字节的价格比旋转磁盘贵很多

So rotating disks are much bigger but they're slower

所以旋转磁盘的容量要大得多，但速度更慢一些

SSDs are smaller and faster

SSD 更小更快

Now if you take...

现在，如果你看一下

If you look at the performance characteristics of these different storage devices relative to CPU

如果你看一下这些不同存储设备相对于 CPU 的性能特征

Over time you get this really interesting graph

随着时间的推移，你会得到这个非常有趣的图表

Now this graph shows on the y-axis access time in nanoseconds  or in a log scale

此图的 y 轴标识访存所需要的时间，单位为纳秒，以 10 的指数为尺度

Okay so each one of these each change in units from 1,000 to 10,000 represents a order of magnitude difference in access time

好的，y 轴上相邻一格的变化，都表示访问时间的一个数量级差异

On the x-axis I've plotted time going from 1985 to 2015

在 x 轴上，我绘制了从 1985 年到 2015 年的时间

And then I've plotted the sort of the the access time or the cycle time of

然后我绘制了各种设备访存需要花费的时间或 CPU 周期时间

The access time of the these devices, disk, SSD, DRAM and SRAM

绘制了硬盘、SSD、DRAN 和 SRAM 访存的时间

And the cycle time of processors

和一个 CPU 周期的时间

So let's look at on the bottom we have the the cycle time of processors over time

让我们先看图表的下方，是 CPU 周期的时间随着历史的发展的变化

And what you see is it's going down at is this sort of exponential rate  from 1985 to 2003

你所看到的是一个 CPU 周期的时间从 1985 年到 2003 年以这种指数速度在下降

There's the doubling basically every 18 months or two years in clock frequency and a resulting

基本上每 18 个月或两年，时钟频率就会加倍，结果是

Halving of the cycle time over this 18-month to two year period

大约过 18 个月到两年，一个 CPU 周期的时间会减半

So this so what what manufacturers did until 2003

所以这就是制造商在 2003 年之前所做的事情

To make their processors faster was a but they would just double the clock frequency

为了使他们的处理器更快，他们只会使时钟频率加倍

They decrease the feature size of the chips that they were making

它们减小了它们制造的芯片的特征尺寸

And that would allow them to put things closer together

这可以让制造商把更多的部件放的更紧密

And then have that and then increase the clock frequency by a proportional amount

然后按比例增加时钟频率

Now this all ended 2003 was an interesting year in computer history

现在这一切都在 2003 年结束，这是计算机历史上有趣的一年

Because of this there's a sort of unfortunate property that the power that you consume

因为有一种不幸的特性，就是 CPU 消耗的电能

Is proportional to your frequency

与其时钟频率成正比

Okay so the more power I mean the higher the frequency the more power you consume

CPU 越强，其时钟频率越高，消耗的功率越大

By 2003 the processor that Intel was getting ready to ship was going to burn about 800 watts of power

到 2003 年，英特尔准备新出品的处理器将耗费大约 800 瓦的功率

Think about 800 watt light bulbs inside your laptop and

想象一下，你的笔记本电脑里面有一个 800 瓦的灯泡（笑

I actually saw an early prototype of one of these devices

我实际上看到了其中一个设备的早期原型

And the the heatsink to absorb the power from the chip was about this big it was about four square inches

吸收芯片热量的散热器大约是四平方英寸大

It's a giant thing just sitting on the motherboard

这在主板上简直是一个庞然大物

So that's what we what we say is that processor design hit the power wall in 2003

所以这就是我们所说的处理器设计在 2003 年触及了能源的瓶颈

They could no longer just continue to increase clock frequencies

他们再也不能继续增加时钟频率

To to get faster to make faster computers

为了制作更快的计算机

And what so what they had to do after 2003

那么他们在 2003 年之后必须做些什么

Instead of increasing the clock frequency and try and set up doubling the clock frequency

而不是增加时钟频率，尝试设置加倍时钟频率

They put more processor cores onto the chips

他们在芯片上放置了更多处理器内核

So now they subdivided a CPU chip into individual processor cores

所以现在他们将 CPU 芯片细分为单独的处理器内核

Each one could execute its own instructions

每个核心都可以执行自己的指令

And then so and by running in parallel

然后通过并行运行

You could do more effective work so the effective cycle time could continue to go down

CPU 可以更有效地工作，因此有效的周期时间可能会继续下降

So what I've what I plotted here on the bottom is the effective cycle time

所以我在底部绘制的是有效循环时间

So basically the the cycle time divided by the number of cores

换言之，是循环时间除以核心数

So here in 2005 that the first systems use two cores

所以在 2005 年，出现了第一个使用两个核心的系统

So now you can run two independent threads or two independent programs

所以你可以运行两个独立的线程或两个独立的程序

And currently it's about four cores server class systems you can get eight cores

当前，它发展到了四核服务器级系统，你可以获得八个核心

And there's even some 12 core chips

甚至还有 12 核芯片

So in the future what's going to happen is that the the clock frequencies are going to stay fairly constant

因此，未来的趋势将会是时钟频率将保持相当的稳定

So you can see the the cycle times are

你可以看到 CPU 周期时间

They actually increased a little bit here and then they're slowly going down but it's generally flat

它们实际上在这里增加了一点，然后它们慢慢地下降，但是通常是平的

And so the only way to really get more performance

所以真正获得更多性能的唯一途径

Go forward is to increase the number of independent course

是增加独立核心的数量

And that's just that's just the way it's got to be

这就是它的方式

Now here in the the black circle the second line I've plotted the access time for SRAM over time

现在，看第二行的黑色圆圈中，我绘制了 SRAM 访问时间的发展过程

And you can see that SRAM is tracking CPU pretty good

你可以看到 SRAM 的情况和 CPU 跟踪地非常好

And it and there's it's an order of magnitude slower but

虽然它的速度要慢一些些

It's tracking the CPU performance pretty well

它很好地跟上了 CPU 性能的发展

DRAM, you can see there's a huge gap between the CPU and the DRAM several orders of magnitude

至于 DRAM，你可以看到 CPU 和 DRAM 之间存在几个数量级的巨大差距

And in the last few years DRAMs have gotten a little better

在过去的几年里，DRAM 已经变得更好了

But they've proven surprisingly difficult to to make faster

但也已经证明非常难以更快地速度进步了

SSDs are kind of in between disks and DRAM

SSD 介于磁盘和 DRAM 之间

And then disks up here you can see at a million nanoseconds that's the that's a millisecond

然后看这里的磁盘的曲线，你可以看到一百万纳秒，就是毫秒级别

So you can see disks are sort of in this in this sort of millisecond range with access times

你可以看到磁盘的访问时间在毫秒范围

And those those that they've gone down a little bit but not really too much

曲线下降了一点点，但还是不怎么够

So the point I want to make is that there's this huge gap between DRAM  SSD disk in and CPUs

所以我想说的是 DRAM、SSD、磁盘和 CPU 之间存在着访问时间的巨大差距

And in some cases it's even getting worse as time goes by so that's a problem right how

而且在某些情况下，随着时间的推移，它甚至会变得越来越糟，因此这是一个问题

Our programs all need data our data is stored in memory and disk

我们的程序都需要数据，我们的数据存储在内存和磁盘中

So if if our if our computers are getting faster

所以如果你的计算机变得越来越快

And our storage devices are are staying relatively the same or relatively slower

我们的存储设备的访问速度却保持相对不变，甚至变得相对较慢

Then we've got a problem right increases in in our in computer performance won't

然后我们就遇到了一个问题，就是我们的计算机性能实际上不会增加

It'll be hard to make our programs run faster

很难让我们的程序运行得更快

Because we'll be limited by the time it takes to to access the data

因为我们会受到访问数据所需时间的限制

Ok so that's that that's sort of the fundamental problem that we have to deal with

好的，这就是我们必须处理的基本问题

And it turns out that the key to bridging this this gap between the CPU and and memory

事实证明，弥合 CPU 和内存之间差距的关键

Is this is this very basic fundamental property of programs called locality

是这个非常根本的程序的基本属性——程序的局部性

Okay and so this is an essential sort of fundamental enduring property of programs

好的，这是程序的一个基本的，持久的属性

So we say that so programs have this property called locality

所以我们说，程序有这个属性，叫做局部性

And what this means is that...

这意味着什么......

I'm sorry I'll just I have to read it because it's it's really accurate definition

对不起，在我给你们讲之前我只需要读一读，因为它是非常准确的定义

So programs tend to use data and instructions whose addresses are near or equal to those that they have used recently

因此，程序倾向于使用其地址接近或等于最近使用过的数据和指令的那些数据和地址

Okay so if a program access is a data item the chances are very high

好的，如果程序访问是一个数据项，那么

That it's going to access that data item or a nearby data item sometime in the near future

它将在不久的将来的某个时间访问该数据项或附近的数据项的可能性非常高

Okay that likelihood that the program is going to access that data item or nearby a data item In the near future

在不久的将来，该程序可能会访问该数据项或附近的数据项

that is this property called locality

这个属性称为局部性

So well does we just typically distinguish two two different kinds of locality

通常，局部性有两种不同的形式

Temporal locality is the property that recently referenced items are likely to be referenced again in the near future

时间局部性是最近引用的存储器位置可能在不久的将来再次被引用的属性

case is if so if you read a variable

例如，你读取了一个变量

Chances are you're going to read that variable again

你有可能再次阅读该变量

For example suppose you're summing into a variable inside of a loop

例如，假设你在循环内，不断累加结果到一个变量

Each loop iteration you're going to access that that variable okay

那循环中的每一次迭代都会访问那个变量，对吧

Spatial locality is that the tendency for items with nearby addresses up that

空间局部性是指引用临近存储器位置的倾向

That items if we access if we access one item chances are high we're going to access a nearby item

如果我们访问了一个存储器位置，那么有很高的可能性我们在将来会访问一个临近位置

Okay so let's look at this little snippet of code and see if we can identify all the different kinds of locality in this code

让我们看看这段代码，看看我们是否可以在此代码中识别出所有不同类型的局部性

So we have two different kinds of of references there's data references

所以我们有两种不同类型引用，首先是数据的引用

And then there's instructions right so we're reading instructions out of memory

然后是对数据的引用，所以我们正在读取内存中的指令

And those instructions are referencing data okay

这些指令再引用数据

So first of all notice that we're we're referencing the elements of an array in succession

首先要注意的是，我们在引用的数组里的元素是连续的

So we're increasing i by one each time and then we're

所以我们每次对变量 i 增加 1

So we're incrementing i through the loop and we're reading a[i]

循环的每一次迭代都自增变量 i，然后读取 a[i]

Okay so this is called a stride-1 reference pattern the

好的，所以这被称为步长为 1 的引用模式

The stride is how much we're incrementing this this index

步长是指我们将这个索引递增多少

So we're since we're incrementing it by one we call that a stride one pattern

因为我们这里的变量i每次递增 1，所以是步长为 1 的引用模式

So what kind of what kind of locality is the these repeated references to a[i]? Spatial or temporal?

对于 a[i] 的这些重复引用，是属于哪一种程序的局部性？空间局部性还是时间局部性？

That spatial, right? Because we're accessing nearby items

是空间局部性，对吧？因为我们正在访问附近的存储器地址

Okay what about the referencing this this variable sum inside the loop

好的，那对于在循环内部，不断引用 sum 这个变量

That's temporal

就体现了程序的时间局部性

Now what about instructions

那现在来考虑一下指令

So we're referencing, where each loop iteration where reference we're executing a sequence of instructions

循环中的每一次迭代，我们引用的都是一系列（相同的）指令

So what kind of locality is that

这体现了哪一种程序局部性原理？

Within each loop iteration?  that's spatial, right?

在每个循环迭代中？是空间局部性对吧？

Because we're just executing a sequence of instructions within each loop iteration

因为我们只是在每次循环迭代中执行一系列（相同的）指令

But then we cycle through the loop repeatedly

但是我们反复地执行这个循环

So we'll chances so each loop iteration we're going to access each of those instructions

因此，在每次循环迭代，我们很有可能将访问那些指令

That we access the previous loop iteration right

每次迭代都访问上一次迭代访问过的指令

So we go up we just keep at we're just going to keep executing the same

随着程序进行，我们只是执行相同的指令

Assembly language instructions that implement this loop body

执行的是相同的，实现此循环体的汇编语言指令

Now in this simple example it's probably this one instruction

现在在这个简单的例子中，它可能就是一条指令

But in general your loop can have multiple instructions

但一般来说，你的循环可以有多个指令

Now when I claim to you I'm one of the one of the main sort of points of this just this whole course

现在，现在我想对你们说的就是这整个课程的主要观点之一

Is that as a professional programmer

作为一个专业的程序员

It's an essential skill that that you be able to look at code and so get a qualitative sense of its locality

这是一项必不可少的技能，你观看代码，就可以获得对其局部性的定性认识

Because as we'll see good locality turns into good performance

因为我们会看到，好的程序局部性带来良好的性能

The way that systems are built these days

这就是如今系统的构建方式

So as a programmer it's very important for you to be able to kind of look at code and get some qualitative sense

因此，作为一名程序员，能够在看到代码时获得一些定性感觉对你来说非常重要

Like yeah that's pretty good locality that's terrible locality right that that's

就像，你可以分析出来，代码的这部分局部性非常好，这部分局部性非常差，

And what you want to do is avoid the terrible locality in your code

你需要做的是避免代码出现差的局部性

So let's look at a simple example here

那么让我们看一个简单的例子吧

To see what I mean by this

一起看看我用这个例子想表达什么意思

So what I'm doing is I'm taking an array a two-dimensional array a

所以我正在做的是我有一个二维数组 a

With m rows and n columns

数组 a 有 m 行和 n 列

And within it a doubly nested loop iterating on I and j

并且在双重嵌套循环中，用索引 i 和 j 来迭代

I'm summing the elements of that array

我正在求该二维数组的所有元素的总和

Okay seems this a very simple operation what could go wrong right

好吧，这似乎是一个非常简单的操作，怎么可能出错呢？

So it turns out if you write this code to have bad locality, it will run order magnitude slower

实际上，如果你以使其具有较差的局部性的方式编写此代码， 则它将以慢一个数量级的速度运行

Okay so if just look at this if you look at this do you think this has good locality or bad locality

好吧，看看这段代码，你认为这段代码的局部性是好的还是差的？

Let's look at the with respect to the accesses of a

让我们看一下关于对数组 a 的访问

Good or bad ?

是好是坏 ？

Well so how is how is a laid out in memory right

数组 a 在内存中是如何布局的呢？

It's row wise all right so see uses used lays out a raised row wise

是行优先的，对吧？数组是以行优先顺序来存储的

So the first all the elements of the first row followed by all the elements

首先是第一行的所有元素

Of the second row followed by all the elements of the third row

然后跟着第二行的所有元素，之后是第三行的所有元素

Okay so how are we accessing this array

好的，我们如何访问这个数组

Look at we're accessing a[i][j] and we're varying j the fastest

看看我们正在访问 a[i][j]，我们正在以最快的速度改变 j

So we hold i constant and then we vary j

所以我们保持 i 不变，然后我们改变 j

And then we access all so we hold the I constant to access row i

然后我们访问所有这一行的元素，所以我们保持 i 不变来访问第 i 行

And then we vary j to access all the columns in that row

然后我们改变 j 来访问该行中的所有列

Okay so each each hitter and then we increase and then we go back and increase i

好的，然后我们回去增加 i

So now we're accessing the next row

所以现在我们正在访问下一行

Okay so if we were to look at the addresses of a[i][j], the sequence of addresses  that are being read

好的，如果我们查看 a[i][j] 的地址，查看正在被读取的地址的序列

Those would correspond to a stride one access and so we'd be accessing all the elements of a sequentially in order

这个序列符合于步长为 1 的引用模式，因此我们将依次按顺序访问所有元素

Okay so that's really good spatial locality right that's the best you can do

好吧，这是非常好的空间局部性，这是你能做到的最好

Now what about and then we have temporal locality on sum so that's good

现在，对于变量 sum 来说，有很好的时间局部性，所以这是好的

Right so everything about this is pretty good so this is the good case

对，所以这个程序的局部性都很好，所以这是好的情况

Now what about this what I've done I've taken the same program

那这个呢，我将上一个相同的程序

And I've just inverted the loops so it's a loop on j first and then on i

我只是颠倒了循环的顺序，它首先在 j 上循环，然后在 i 上循环

And then I just have the same inner loop body

然后内部循环体是相同的

Now what does that do to this what does that do to the spatial locality of our accesses okay

现在，这对我们访存的空间局部性有了什么影响呢？

-Yes -Terrible special locality

学生：非常糟糕的空间局部性

Terrible! Because it's going, you should be offended when you see this, this is awful

非常糟糕！对，你看到这段代码的时候应该觉得被冒犯了，简直糟糕透了

But it's terrible right? Because look it

很糟糕，对吧？因为看起来

So we're now we're holding j

所以我们现在做的事情就是

We're holding j constant and then we're iterating through the j-th element of each row so that's skipping

我们保持 j 不变，然后我们遍历每一行的第 j 个元素，这是在内存中跳跃

We have n we have n elements in each row so we're doing a stride n access through memory

我们在每行中都有 n 个元素，因此我们是以步长为 n 的模式来对内存进行访问

So we're going like this

所以我们就像是这样

And then we're incrementing then we're looking then we're incrementing the column by one and then we're doing this again

访问一个数，然后将列递增 1，然后我们再次这样做（步长为 n 的访问模式）

So it's terrible spatial locality this is the worst spatial locality we could get

所以这是一个糟糕的空间局部性，这是我们可以获得的最差的空间局部性

Now let's look at a three dimensional array

现在让我们来看一个三维数组

And let me ask you that let me post the following question

我现在提出以下问题

Can you based on this sort of qualitative idea that

你能否基于这种定性观念

This idea that you want you want to try to get a stride one reference pattern

这个观念是你最好需要尝试使用步长为 1 的访问模式

Okay so how would you permute these given this inner body

给出这个循环体，你要怎么置换

a[k][i][j] how would you permute these loop indices to give stride one reference pattern

a[k][i][j]，你要如何置换循环的顺序，使它满足步长为 1 的引用模式

Okay that's right, kij is right

好吧，这是正确的，循环的先后次序应该是 k、i、j

So what in general we want to do is we want to go going from right to left

所以通常我们想做的是要从右到左

We want we want those indices to be changing the fastest

我们希望右边的这些索引变化是最快的

So we want j .. we want k and i to be held constant and then we want to change j

我们希望 k 和 i 保持不变，然后我们想先要改变 j

Then we want to increment i and then for that value that those values of k and i

然后再增加 i，然后再增加 k

We want to want to sequence through all the the values of j again

我们想要按照顺序来访问所有的 j 值

Okay

好的

Okay so we've looked at properties of technology of storage technologies

好的，我们已经研究了一些存储技术的技术属性

And well we and there's this sort of basic sort of fundamental principle that cheaper storage

我们得到了这种基本原则，即更便宜的存储设备……

You bigger storage higher capacity storage is cheaper

……存储容量越大的存储设备，越便宜

More expensive storage is smaller

更昂贵的存储设备，其存储空间会设计得更小

Because we just don't have that we don't we can't spend enough money

因为我们不能花太多的钱

There's this gap there's this gap between our storage devices and the CPU

我们的存储设备和 CPU 之间存在这种访问速度的差距

That is in at least in the case of disks are getting bigger

至少在磁盘容量变得越来越大的情况下

And we have programs that exhibit locality

但好在，程序具有局部性这个原理

Okay so these three things these properties of storage technologies

好的，这三件事，即存储技术的这些特性

And properties of our programs

和我们的程序的局部性属性

Complement each other in this beautiful way to suggest and inform the design of our storage systems

相互补充得非常完美，为人们提供一种设计怎样存储系统的建议和信息

And this design is something called a memory hierarchy

这种设计被称为存储器层次结构

Okay here's the idea of a memory hierarchy

好的，这是就是存储器层次结构的概念

You layer instead of a flat memory system you now

你将内存系统分层设计，而不是单一的平层

You create your memory system as a hierarchy of devices

将存储器系统设计为存储设备的层次结构

And at the top of the at the top of this hierarchy

在这个层次结构的顶部

You have your smaller faster and more expensive storage devices

你拥有存储容量较小，访问速度更快，但也更昂贵的存储设备

So at the very top you have registers

所以在最顶层的是寄存器

Which are which can be accessed and within one cycle right one instruction

寄存器在每一个 CPU 周期，每执行一条指令都可以被访问

While that instructions executing can access read and write into a register

指令执行期间可以读写寄存器

Okay so registers are at the top of the hierarchy

所以寄存器是位于存储器层次结构的顶部

But because those are in custom silicon they're very expensive right

但由于这些都是定制芯片，因此它们非常昂贵

The fabrication plants to make processors cost billions of dollars

生产处理器的制造工厂耗资数十亿美元

Okay so this is the most expensive and

好的，所以这是最贵的

Because of that it's also the smallest we've only got 16 registers at the top of the hierarchy

因为它的容量也是最小的，我们在层次结构的顶部只有 16 个寄存器

Now below that we put one or more SRAM memories remember SRAM is faster

在接下来一层是一个或多个 SRAM，SRAM 是更快的一种内存

It's the fastest kind of memory

SRAM 是更快的一种内存

So we put one or more so-called caches cache memories built out of SRAM

我们设置一个或多个所谓的高速缓存存储器，是使用 SRAM 制作的

in the processor chip itself

这也是在处理器芯片内部的

And then and these caches because they're made out of SRAM they're on the order of megabytes in size

这些缓存，因为它们是由 SRAM 制成的，它们的大小是兆字节（单位为 MB）

Okay they're much bigger than registers but they're they're megabytes

它们比寄存器大得多，但它们也只是兆字节这么大

Okay which if we look and then beneath that is our

再接下来一层就是

Main memory which is built out of DRAMs and those can be gigabytes, tens of gigabytes on modern systems

再接下来一层就是 DRAM 所做的主存，主存在现代系统中可以有十几个 GB 的大小

And then below that is our local disks

再接下来一层就是磁盘

And we can even have lower layers like web servers that are storing you know for storing stuff on google

我们甚至可以把像网络服务器这样的东西认为是更低的一层，例如在谷歌上存储的东西

That you can think of that as just part of our our hierarchy

你可以将其视为我们存储器层次结构的一部分

Now here's the here's the key idea and a higher in a in a memory hierarchy

现在要介绍一个这里是关键点，在存储器层次结构中

Each level in this hierarchy holds data that's retrieved from the next lower level

存储器层次结构中的每一层都包含从下一个较低级别层次所检索的数据

Okay so caches hold registers hold data that's that's stored in the l1 cache

好的，CPU 寄存器保存着从 L1 高速缓存中取出的数据

The L1 cache holds data that's retrieved from the L2 cache the L3 cache holds data  that's restored

L1 高速缓存保存从 L2 高速缓存中检索的数据

That's that's retrieved from main memory, main memory holds data that's retrieved from secondary disk and so on

L3 高速缓存从主存从取出数据，主存又保存着从磁盘取得的数据，依此类推

Now as we'll see the that the reason memory systems are designed like this

内存系统设计如此的原因

Is that they when you have this kind of system

当你拥有这种系统时

This you can access in general you can access your data at the speed of the fastest item in the...

一般来说，在层次结构的顶部，你可以以最快的方式来访问内存

And at the top of the hierarchy

一般来说，在层次结构的顶部，你可以以最快的方式来访问内存

So that's the fastest

所以这是最快的

But with the cost of the storage at the lower part of the hierarchy

但是在层次结构的较低层，访问速度较慢

Okay so this this works all because of an idea called caching

好的，所以这一切都有效，因为一个叫做缓存的想法

So a cache and ... to took to a computer scientist is a

所以缓存对计算机科学家来说

It's a smaller faster storage device that acts as a staging area for the data in a larger slower device

它是一个更小的更快的存储设备，充当更慢的设备中的数据的暂存区域

So just like like here you can think of your main memory is a cache for data

所以就像在这里一样，你可以把你的主存认为是存储在磁盘上的数据的缓存

That's stored on disk right you read memory from disk and then you store it in main memory

你从磁盘读取数据，然后将其存储在主存中

Okay you can think of the main memory as a staging area

对吧，你可以把主存储器想象成一个临时区域

So once you get the data from the disk you don't access it again on the disk you access it in memory which is much faster

一旦从磁盘获取数据，就不会再在磁盘上访问它，而是在内存中访问它，速度要快得多

Ok so this idea propagates all the way up the hierarchy

好的，这个想法一直在层次结构中传播

Okay so we you can think of a cache on

好的，我们可以这么想象缓存

One way to think of a cache is imagine your backpack when you're getting ready to come to school in the morning

可以通过想象你的背包来比喻缓存，当你早上要来上学的时候

So you're in your apartment which is kind of far away from school

比如你的公寓离学校有点远

So before you come into school you take items from from your house

所以在你上学之前，你要带一些东西

And you put them in your backpack right

你把它们放在你的背包里

Then you come to school if you need those items you get there in your backpack

你背着包来上学，然后如果你需要用到那些东西你就从背包中拿出来

You know if you didn't do that

如果你不这样做

Every time you needed something you'd have to walk back home and get it  and then walk back to school

每次你需要用到某样东西，你都必须走回家拿，然后再带回学校

All right so it's so the idea of caching is very you know it's a very familiar kind of simple notion

好吧所以这就是缓存的概念，你知道它是一种非常熟悉的简单概念

But it turns out to be quite powerful and it shows up in all parts of computer systems

但事实证明它非常强大，并且它出现在计算机系统的所有部分中

Okay so so what we say is that for each level k in the hierarchy

对于存储器层次结构中的每一层，我们现在设为第 k 层

The the faster, smaller device at level k serves as a cache

第 k 层的，更快更小的存储设备，都是缓存

For the larger slower device at level k+1

都是对于第 k + 1 级较大较慢的存储设备的缓存

And remember our our levels go from so l0 is the highest

要记住，体系的层次中从 L0 开始是最高的

So this the smallest lowest level is actually the highest

所以这个最小的数字实际上是最高的级别

The further step in the ... in the hierarchy and as we increase the levels

层次结构中每进一步，我们提高级别

We're going down the hierarchy

在层次结构中不断深入

Now why do they work so this is this is a really fundamental idea

现在他们为什么这么做，所以这是一个非常基本的想法

They work because of locality

这个结构之所以有效就是由于程序的局部性原理

So because of locality programs tend to access data that's stored at level k

由于局部性原理，程序倾向于访问存储在第 k 层的数据

More often than they access data at level k+1 o

比访问第 k + 1 级的数据更常见

Okay so if we access an item at level +1

好的，如果我们访问第 k + 1 层存储单元

We can move it up to level k chances are because of locality we're going to access it again

我们会将其拷贝到第 k 层，因为我们很有可能将再次访问它

Okay so now we're accessing the data at level k multiple times at the rate at the speed of level k

好的，现在我们以第 k 层的设备访问速度，多次访问第 k 层的数据

Okay not at the speed of level k plus one okay so that's

而不是以第 k + 1 层的速度

That's the fun the fundal fundamental idea

这就是这个层次结构概念的有趣之处

And because we're not accessing data at level k+1 as often

而且因为我们不经常访问第 k + 1 层的数据

We can afford to use slower storage devices which are cheaper

我们可以负担得起使用更便宜的速度较慢的存储设备

In this and thus we c0an make them bigger and cheaper per bit

在这方面，因此我们可以使它们容量更大，存储每比特的价格更便宜

So what this does is the hierarchy creates a a large pool of storage

层次结构创建了一个大型存储池

That's roughly about the size of the lowest level

其存储容量大小大约等于最底层存储设备的大小

That can be accessed at the speed at the highest level

却可以以最高层存储设备的速度来访问

All right let's let's look at how caching works in a general way

好吧让我们来看看缓存的一般方式工作

And then we'll see on thursday how these hardware cache memories work

然后我们将在星期四学习其中的细节

Okay but like I said caching is a very general idea that can be applied at all levels in the hierarchy

但就像我说的，缓存是一个非常通用的概念，可以应用于存储器层次结构中的所有层

So here we have a cache - so the in all kinds of most caches there's some kind of transfer unit

所以这里我们有一个缓存，在各种缓存中都有某种传输单元

To go from one level to the next

在层级之间来回拷贝

So here we have at this at this upper level

所以我们在上层有这个

We have a what we'll call the cache that can hold four blocks

我们有一个称之为可以容纳四个块的缓存

So our our memory and then at the lower level we have memory

我们又有在底层的内存

And this memory is partitioned into blocks of some fixed size that's this

并且这个内存被划分为一些固定大小的块

That's the way cache is at nearly near the upper part of the hierarchy work

这就是接近存储器层次结构上层的缓存的工作方式

Now at the lower levels like if you're accessing data say from a web server

若处于较低级别，就像你从 Web 服务器访问数据一样

Then the the data is partitioned into files typically

在这个例子中，通常将数据划分为文件

Okay but it upper levels the data is partitioned into blocks so just suppose this is main memory

但它的上层数据被分区为块，所以假设这是主存

And then above that we have a that consists of a bunch of these blocks

然后，在这之上，有由一堆这些块组成的（高速缓存）

So we just take the memory and partition into blocks where each block is the same number of bytes

所以我们只需将内存分成一个个的块，每个块的字节数相同

And then data will be transferred between memory and the cache in block size transfer units

然后，数据将以块大小为传输单位在内存和高速缓存之间传输

Okay so if you need data from the memory if the cache needs data from the memory it'll grab a whole block

如果你需要来自内存的数据，如果告诉缓存需要来自主存的数据，那么它将获取整个块

And then at any point in time the cache holds a subset of the the blocks in main memory

然后在任何时间点，高速缓存都保存主存储器中块的一个子集

Okay so this this cache is much faster but it's also much slower

好的，所以这个缓存要快得多，但速度也慢得多（口误，应该是容量更小）

And because of that and it's much smaller

因此，它的存储容量要小得多......

I'm sorry it's much faster but it's it's much more expensive because it's faster it's more expensive

抱歉，它的速度要快得多，但它的价格却要贵得多

And because it's more expensive it's smaller

而且因为它更贵，所以它存储容量更小

Now suppose the cache wants to reference say that the CPU asks for data that's contained in block four

现在假设缓存要引用某个内存块，假设 CPU 现在要求第 4 块中包含的数据

So it looks it looks to see if the data is in the cache it's not

CPU 首先查看这个数据是否存在于高速缓存中

So the cache asks the memory to give it block four

（第 4 块不存在于高速缓存中）所以缓存要求主存给它第 4 块

So that block is copied from memory into the cache

这样这个块就会从内存复制到缓存中

Overwriting the one of the existing in this case block eight it will overwrite block eight

覆盖缓存其中一个现有的块 8

So now now block four is is in our cache

所以现在块 4 存在于我们的缓存中

Now suppose now now suppose the CPU asks for a some data that's in block ten

现在假设 CPU 请求第 10 块中的一些数据

That gets copied up and and we overwrite that that block

这样第 10 块会被复制，又覆盖掉缓存中的那个（第 14）块

Now the whole idea of storing it in the cache is that we're hoping that the program that's executing on the CPU

现在将块复制到缓存中的想法是，我们希望在 CPU 上执行的程序

Will reuse one of those blocks we just spent all the time

将重用我们复制到高速缓存中的一个块

We went to all this trouble to copy it from memory to to this cache  and we know that's slow

我们费力地从内存复制块到缓存，我们知道这很慢

So now suppose that the CPU needs some data in block  b in this case fourteen

所以现在假设 CPU 需要块 b 中的一些数据，在这个例子下是块号为 14 的块

Okay so it needs a memory word that's stored that was originally stored in memory it in block fourteen

好吧所以它需要存储第 14 块中的一个字

Well now this cache can just return that's what we call a hit right so the

现在缓存内有这个块，因此可以直接返回，我们称之为缓存命中（cache hit）

Block that we access is in the cache so that's good hits are good

我们要访问的块正位于缓存中，这叫缓存命中，这是很好的

Because now we can return that block directly to CPU

因为现在我们可以将该块直接返回给CPU

And this this memory is much faster than if we had to go all the way to main memory to the DRAM

而且使用高速缓存的访问速度比如果要去访问 DRAM 主存要快得多

Okay so the SRAM much faster than the DRAM

SRAM 比 DRAM 快得多

So the CPU gets that block 14 much faster than it would have

相比要到主存中去取得这个块，通过这种方式 CPU 非常迅速地取得第 14 个块

If it had just gone all the way to memory

相比要到主存中去取得这个块，通过这种方式 CPU 非常迅速地取得第 14 个块

Okay the sort of other the the opposite of a hit is a miss

好吧，与缓存命中刚好相反的是缓存不命中（cache miss）

So suppose the CPU s for block twelve

假设 CPU 现在请求第 12 块

The cache looks for that block can't find it

在高速缓存中查无此块

That's a miss, so the the cash has to ask that the main memory the DRAM for block 12

这就是缓存不命中，高速缓存需要从主存中取出第 12 块

Where it gets copied into the cache and then it can return that

复制第 12 块到高速缓存中，然后可以返回给 CPU

So that takes longer right so the CPU has to wait for that block to be ex(tracted) to be fetched from memory

所以这需要更长的时间，因此 CPU 必须等待高速缓存从内存中取出该块

And so misses are slow so hits are good because they're fast

所以一旦出现缓存不命中，访问速度就会很慢。所以缓存命中很好，因为很快

Misses are bad because they're they're slow

缓存不命中很糟糕，因为会很慢

Now we typically distinguish between several different kinds of caches

我们通常区分几种不同的缓存不命中的种类

So the first kind of miss is a cold miss or a compulsory miss

因此，第一种是冷不命中（cold miss）或强制不命中（compulsory miss）

Which is caused because there's just nothing in the cache

这是因为高速缓存中没有任何的数据

Initially caches they're empty they have no blocks and as we fetch

最初缓存它们是空的，没有存储任何块，当我们要读取数据时

As we fetch blocks from the lower level from the next the next level and put them in the cache

当我们要读取数据时就要从下一级获取块，将它们放入缓存中

The cache will slowly fill up with blocks

缓存将慢慢填满

And we'll get and that will increase the likelihood of hits

也就增加了缓存命中的可能性

But when the cache is empty we're going to miss every time, right?

但是当缓存为空时，每一次访存都肯定会缓存不命中，对吧？

So there's just no way to avoid cold misses right you got

所以没有办法避免冷不命中

Oh so this is called warming up your cache so as you load data items into the cache

将数据项加载到空的缓存中，这称为缓存的暖身

Initially it's cold and as you add more items you're warming it up meaning that you're increasing the likelihood of a hit

最初缓存是空的，当往里添加越多的数据块，热身意味着增加了缓存命中的可能性

Now there's a there's another sort of symmetric kind of miss which is called a capacity miss

还有一种与冷不命中对应的情况，称为容量不命中（capacity miss）

And these misses are due to the fact that the cache is just a certain size right you just can't

容量不命中的原因是高速缓存的大小是有限的，你不能（容纳超过缓存大小的工作集）

In the example we looked at we only had four blocks

在我们看到的例子中，我们的高速缓存只有四个块的大小

So if we're trying, if our, if our temporal locality involves eight blocks

如果我们的程序的局部性需要用到包含 8 个块的数据

You know say if the loop that we're accessing is  is accessing elements in array

假设我们正在循环访问数组中的元素，这个数组包含 8 个块的数据，

That that consists of eight blocks there's just not enough room to store eight blocks and that four block cache

那么自然容量仅有 4 个块的高速缓存无法放下整个 8 个块的数组

So we're going to get misses right we would need a bigger cache to be able to satisfy and store those eight blocks

因此，我们将会遇到容量不命中，我们需要更大的缓存才能存储这 8 个块

And if we had a big enough cache then we get good hit rate right if we could store all the blocks

如果我们有足够大的缓存，那么就会有良好的命中率

In our cache then we then the cache could take advantage of the spatial and temporal locality within that program

如果我们可以在缓存中存储所有块，然后缓存可以利用该程序中的空间和时间局部性

So in general what we call this set of blocks at any point in time when a program is running

所以一般来说，在程序运行的任何时候，

We call the set of blocks that are sort of being accessed over and over again the working set

我们将这一些不断被程序访问的块称之为工作集（working set）

And so your working set and the working set will change you know as you go from loop to loop  from function to function

工作集是会改变的，当你的程序从一个循环执行到另一个循环，从一个函数到另一个函数时

But at a point in time in your program when

但是在程序执行中的某个时间点

It you have this idea of a working set which is sort of the blocks that you need to have stored in your cache

有一个工作集的概念，它就是你需要存储在缓存中的块

Ok and well so when you're working set size exceeds your cache size then you get capacity misses

好的，所以当你的工作集大小超过你的缓存大小时，就会发生容量不命中

There's this other kind of weird miss called the conflict miss

还有另一种奇怪的缓存不命中，称为冲突未命中

Which has to do with the way that caches are often implemented

这与缓存的实现方式有关

So the idea is that most caches especially hardware caches because they're they have to be simple

这里的概念是，大多数缓存，特别是硬件缓存，因为它们必须设计地较为简单

They have they limit where a block can be placed to some

限制了块可以被放置的位置

Small set of positions in the cache

块可以被放在缓存中的一小组位置

So like one of the the simplest models is to just take

像最简单的模型之一就是

Block I can only be placed in block I mod the cache size

块号为 i 的第 i 块只能放在（i mod 缓存大小）处

So in our that that little cache we saw that had four blocks

所以假设我们有一个缓存，可以容纳四个块

We would take we would take block I from memory and we would stick it at block I mod 4

当我们从主存中读取一个块号为 i 的块时，会将其放到缓存中的（i mod 4）处

So block 0 would go at block 0 in our cache

所以主存中取出的块 0 将存在我们的缓存中的块 0 处

As would block 4 and as would block 8. Block 9 would go into block 1 in the cache

第 4、第 8 块都会放在 cache 中的第 0 块，第 9 块将放在 cache 中的第 1 块

And that's when that happens suppose suppose we use that model

假设我们使用该模型，当发生这种情况时

So we're going to take block i and we're going to put it we can only place it in the cache

对于块号为 i 的块，我们只能将其放在 cache 中的（i mod 4）处

At block i mod 4

对于块号为 i 的块，我们只能将其放在 cache 中的（i mod 4）处

Now suppose our suppose our reference pattern involves from memory block zero block four and block eight

假设我们从主存中要引用的数据对象是块 0、块 4、块 8

It's only three blocks so we have we have enough room in the cache to store those three blocks

只引用三个块，所以我们在缓存中有足够的空间来存储这三个区块

But because of the way we've decided to place blocks each block will be will evict

但由于映射缓存块的方式，每一次拷贝新的块到 cache 时都会导致驱逐另一个块

When we access block four it'll go into block zero in the cache

当我们访问第 4 块时，它将进入高速缓存中第 0 块已经占有的位置

When we access blocked four in the cache

当我们在高速缓存中访问第 4 块时

It'll overwrite that block and it'll go into block zero in the cache

它会覆盖第 0 块所在的位置

And so because of this it's really the access pattern conspiring with the  algorithm

因此，这种访问模式与用于映射块的算法密切相关

That we're using for placing blocks

因此，这种访问模式与用于映射块的算法密切相关

Okay so because of this we have plenty of room in the cache

因此，即使我们有足够大的缓存

But because of this sort of the access pattern conspiring with the placement algorithm

但由于这种访问模式和映射算法

We get misses every time

缓存会一直不命中

We'll see how conflict miss works in detail when we study your caches tomorrow

我们将在明天研究 cache 中冲突不命中的细节

So

所以

So this is these these caches exist everywhere in the memory hierarchy and

所以这就是缓存存在于存储器层次结构中的任何地方的体现

So all of them are caches of one form or another right

所以它们都是各种形式的缓存

So you can think of the registers as a type of cache

你可以将寄存器视为一种缓存

What are they cache for eight byte words

它们缓存的是八个字节的字

Okay where's it cached it's cached right on the CPU itself

好吧，它被缓存于何处？在 CPU 上

What's the latency? It's instant and happens within an instruction

延迟呢？没有延迟，发送在一条指令的执行周期内

And then who manages the cache somebody has to manage the cache when

然后是谁管理缓存？必须要有东西管理缓存

When there's a request to load an item from the lower level in the hierarchy

当有请求从层次结构中的较低层读取内容时

Something has to decide what to do with that where to put it in the cache that's called managing the cache

必须有一个过程决定如何处理这个请求， 如何将其放入的缓存中的某一位置，我们称之为缓存管理

Well in this case the compiler manages the cache

在这种情况下，由编译器管理缓存

When you when you compile your C code the compiler figures out which register

当你编译 C 语言代码时，编译器会确定由哪个寄存器

Data items from memory are going to go into okay

编译器会确定由哪个寄存器来存储来自内存的数据项

So TLB this is something this is a cache that's used in virtual memory

TLB（翻译后备缓冲，Translation Lookaside Buffer）      是一个在虚拟内存中使用的缓存

Then there's these hardware caches called l1 and l2 caches

然后是这些称为 L1 和 L2 缓存的硬件缓存

So they store 64 byte blocks on modern Intel systems

它们在现代英特尔系统上存储 64 字节块

And they're cached on the CPU chip itself in SRAM that are built right into the CPU chip

它们被缓存于 CPU 芯片上，由 SRAM 制成，集成在 CPU 上

And depending on whether l1 caches to on core i7s have a latency of 4 cycles

L1 缓存在酷睿 i7 上的延迟是 4 个时钟周期

And l2 has a latency of 10 cycles

L2 缓存的延迟是 10 个 CPU 周期

And both of these are managed by hardware

这两者都是由硬件管理的

So when you when the CPU fetches an item from the l1 cache hardware figure finds it

所以，当 CPU 要从 L1 缓存中读取一个内容时，由硬件来管理

And if there's a miss and a block is loaded from l2, hardware in the l1 cache figures out where to put it

如果出现了未命中，就会从 L2 缓存中加载一个块，L1 缓存中的硬件来决定在哪里存放这个块

Ok so all this is done without any intervention, by hardware

好的，所有这些都是在没有硬件干预的情况下完成的

Disks contain buffer operating systems maintain buffer caches

磁盘包含由操作系统维护的缓冲区缓存

So in this case what's cached is portions of files

在这种情况下，缓存的是文件的一部分

Ok and they're cached in main memory

好的，他们被缓存在主存中

And latency to main memories about a hundred cycles or so

缓存到主存的延迟大约一百个时钟周期左右

And these are managed by the operating system

这些都是由操作系统管理的

So the operating system reserves a portion of memory to store files that you've loaded so

因此，操作系统会保留一部分内存来存储你已加载的文件

So the operating system exploits locality if you if you read a file

因此，如果你读取文件，操作系统将利用本地性

And then start reading, referencing bytes from that file. It will actually be served from the

然后开始从该文件中读取字节，它实际上将从主存中的文件缓存被读取

file cache and it won't go out to disk

而不是去磁盘上读取

Networks maintain caches like things like NFS and AFS maintain local caches on disk

网络也维护着一份本地地盘的缓存，例如网络文件系统（Network File System）和安德鲁文件系统（Andrew File System）

Your browser has a cache so when it fetches files from from servers

浏览器有缓存机制，因此从服务器获取文件时

It stores those files locally on disk so if you reference those web pages again

浏览器将会把这些文件本地存储在磁盘上，以便再次引用这些网页

They're served from from your local disk rather than going all the way across the network

然后这些文件就会从你的本地磁盘读取，而不是一直通过网络重新请求

Ok so the point is that these caches exist everywhere in the memory hierarchy

好的，这里的理念就是，缓存机制存在于存储器层次结构中的任何位置

And they're all based on the same principles they're just implemented in different ways

而且它们都基于相同的原则，它们只是以不同的方式来实现

Ok so just to summarize what we've what we've done today

好的，现在总结一下我们今天所学的东西

We've seen that there's there's a gap between the CPU and our storage devices that continues to increase

我们学习了 CPU 和存储器设备之间存在着访问速度的巨大差距，而且在不断扩大

We've seen that well-written programs have this property called locality

我们学习了编写良好的程序具有称为程序性的属性

And we've seen that caching by taking by using caching

我们了解了缓存的概念

We can build a memory hierarchy that takes advantage of locality and programs

利用缓存的概念和程序的局部性原理，我们可以构建存储器层次结构

And allows us to build storage systems that where we can access data at the rate of the fastest device

允许我们构建存储系统，以便我们以最快的设备速率访问数据

But at the cost and capacity of the devices at the the lowest level

但却有着底层设备容量大，造价低廉的优点

Ok so thursday we're going to look at a very specific part of the hierarchy called cache memories

好的，星期四我们将具体学习存储器层次结构的一个非常具体的部分，高速缓存存储器
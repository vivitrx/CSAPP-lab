大家下午好

欢迎！很高兴见到你们

希望你们已经开始你们的「attack labs」

每个人都开始了吗？我想现在是个好时候开始了

不管怎样，希望你们喜欢，这个实验在本学期是新设计的

我认为这个实验非常有趣，也很新鲜很前卫

今天我们要讲的是……

今天我们要讲的话题是关于存储器层次结构的

至今为止，我们在课上讨论的内存

当我们在学习汇编语言程序的时候

我们仅仅是把内存当作一个字节数组

可以用地址作为下标来访问的一个大的字节数组

但实际上存储系统是一个非常复杂的设备层次结构

提供了一个抽象，把内存结构抽象成一个大的线性数组

所以，我们今天要探寻存储器层次结构是怎么构建的

至于为什么要这么做

我们可以体会到多种存储设备之间属性的美妙融合

以及程序的属性在这当中起到的作用

这个美妙的设计被称为存储器系统结构

所以我们现在以一个较高的视角快速地概览存储技术和趋势

我们现在不会陷入一大堆的细节

学习这些技术和属性，关键点是

有一些决定着性能和运行速度的，最基本最核心的属性

也决定了性能和速度的限制

所以我希望你们首先对这些概念和属性有一个高层次的理解

然后我们会学习一个程序所具有的属性，叫做程序的局部性

我们将会看到局部性和存储设备的特性

合在一起，建议把内存系统设计成一种层次结构

好的，下面我们首先来看一下内存的概念

现在大多数人所熟悉的内存其实叫做随机访问存储器（RAM）

它一般都是被打包成芯片

然后你有很多个这样的芯片，组合起来就成为你的主存

最基本的存储单位称为单元，一个单元存储一个 bit

RAM 可以分为两种

一种是 SRAM 另一种是 DRAM，它们之间是根据存储单元实现方式来区分的

所以...

例如，DRAM 只需要一个晶体管去存储一比特，而 SRAM 更复杂，需要约 4 或 6 个晶体管

所以 SRAM 的成本会高得多

因为 SRAM 的每一个存储单元都比 DRAM 复杂的多

但 SRAM 的速度也比 DRAM 快一个数量级

他俩也有一些其他的性质

DRAM 是需要被刷新的

如果你没有用一定的电​​压去充电

它就会丢失电荷，丢失所保存的信息，所以 DRAM 是需要插着电用的

如果有在充电，那就不需要被刷新

SRAM 就比 DRAM 更加地可靠

所以不太需要进行错误检测和纠正

因此。SRAM 比 DRAM 更小，速度更快

所以，我们将 SRAM 用于那些内存容量小但速度非常快的芯片中，叫做高速缓存

我们将在星期四学习这些有关高速缓存的话题

相比之下，DRAM 被广泛运用于主存，以及图形显卡中的帧缓存中

现在 DRAM 和 SRAM 都是易失的，意味着如果断电，就会丢失它们所保存的信息

这也是为什么当你关掉电脑后，你会丢掉所有内存中的东西

再把电脑打开后，你需要从硬盘中重新加载所有东西

有另一种存储器，称为非易失性存储器，即使断电的情况下也可以保存其中的内容

很多这些东西被称为只读内存

因此，这些非易失性存储器的通用名称是只读存储器（ROM）

在以前，很多最初的不同类型的 ROM

它们只可以在其芯片生产期间被硬编码一次

然后可以用 20 或 30 年的时间

现在，ROM 的编程方式和删除方式都有所改进

它们可以被重新编码

今天我们拥有的现代形式的只读内存被称为闪存

它提供了擦除功能，你可以删除闪存上面的存储块

缺点是闪存约在十万次擦除之后就会磨损了

你可以擦除然后重新编码约十万次后它就会损坏

非易失性存储器可以在固件和软件中使用

非易失性存储器可以在固件和软件中使用

可以对 ROM 进行硬编码

当你开启电脑时会调用的 BIOS

以及开机后执行的最初的指令，都存储在 ROM 中

如果你想知道这些东西来自哪里，那么它们就存储在 ROM 中

然后有一个 boot 引导程序

越来越多的信息和指令都被装载到内存中

你们知道 I/O 吧？I/O 设备中也有小型的计算机，称为控制器

控制器由存储在 ROM 中的指令和数据组成

你还可以在这些固态硬盘（SSD）中看到它们

系统仍然把它们当作旋转的硬盘

但它们实际上是由闪存构成的

就是你在 U 盘、智能手机、平板电脑和笔记本电脑中能看到的那些

现在，它们甚至也在服务器中被使用

主存是通过一些电子线路连接到 CPU 的，这被称为主线（bus）

数据流就可以从内存和 CPU 芯片之间来回传输

CPU 芯片中有一些寄存器，例如这些是通用寄存器：％rax，％rdi 等等

有一个算术逻辑单元会从寄存器文件读写数据

然后对数据进行一定的算术运算和逻辑运算

如果指令需要访存

所以你需要执行一个移动指令 (mov) ，移动指令会读写内存

然后由总线接口处理，该接口连接与另一个接口相连接，我们称之为系统总线

然后它连接到 I/O 桥

这是另一个芯片集合，我所称的 I/O 桥，英特尔称之为芯片组

是与 CPU 芯片区分开来一个芯片集合

然后 I/O 桥连接到另一条主线，叫做存储器主线，连接 I/O 桥与主存

好的，这只是一种抽象，我不希望你们太在字面意义上较真

但它让你了解信息如何在系统中流动

现代系统使用的专有总线设计，它们非常神秘且越来越复杂

所以我们才在这里使用一个非常简易的总线系统抽象

现在，假设你执行了一个装载操作，像是执行 movq 指令

将 A 地址处的 8 个字节加载到寄存器 %rax

之所以我们称之为加载（load），是从 CPU 的角度出发来考虑的

我们是加载数据到 CPU 中

但实际上我们是从主存中加载数据到 CPU 的

所以当 CPU 执行 movq 指令时，是像这样进行的

首先，CPU 将 A 的地址放到存储器主线上

然后主存储器感知到这个信号后，读取这个地址 A 处 8 字节的内容

也就是它会从该地址取得一个 8 字节的字的内容然后将其放回总线上

这些比特会在 I/O 桥上传递回总线接口

然后 CPU 从总线数据中读取这个字 x，然后放到寄存器 %rax 中

然后写入是一个相似的过程

这里我们执行一个指令 movq，将寄存器 %rax 的内容写入主存中地址为 A 的位置

像以前一样，起初，CPU 也将地址写到总线上

主存读取这个地址，然后等待数据到达总线

然后 CPU 将寄存器 %rax 的内容放到总线上

这些数据传输到主存

主存读取这些数据，将其存放到地址 A 处

好，其中的关键点在于其中的操作

也就是寄存器的读写

因为寄存器文件是很接近算术逻辑单元的，这一切都发生在大约几个 CPU 周期内

寄存器文件很接近算术逻辑单元

所以这些操作的速度都很快

然而，内存实际上是非常远离 CPU 的一些芯片组

当你需要读写内存时，那么会发生很多事情

你必须在总线上做多个操作，数据必须通过该总线传播，所有这些操作都需要时间

所以，对于内存的读写，典型地都需要大约 50 或 100 纳秒

而寄存器之间的一些操作所需时间甚至不到 1 纳秒

所以它们之间大约差了两个数量级

如果你需要离开 CPU 芯片，到主存那儿去取一些东西

好，这就是内存系统引入的第一个损耗

现在还有另一项广泛应用的存储技术就是硬盘

不知道你们有没有拆过硬盘，蛮有趣的，硬盘其实是一系列的盘片

每个盘片都涂有磁性材料

然后在该磁性材料中编码 1 和 0 的二进制位

有一个部件叫做传动臂，铰接在这里

然后它可以漂浮在盘片上，它漂浮在盘片上方的薄薄一层空气中

在最末端有一个读/写头，可以感知编码位的磁场变化

这些盘片像逆时针一样旋转，这样磁臂可以前后移动

所以有很多齿轮等机械装置，这些都是机械设备

所以旋转磁盘的机械性质

意味着它会比 DRAM 和 SRAM 慢

而且它还有电子设备，就像固件中的一台小电脑一样

控制了驱动器的操作，该驱动器控制磁臂如何来回移动

并且控制如何从读/写头读取数据

我们来讨论一些细节，我们可以认为磁盘是由盘片组成的

一个盘片有两个表面，上面和下面

每一个表面都包含一系列的同心圆，称之为磁道

每一个磁道包含很多个扇区，扇区存储着数据

典型地，一个扇区存储 512 个 bit...... 不好意思，是 512 个字节

在这些「磁道」之间有一些空隙（注：这里口误，应为扇区之间）

这些空隙是不保存数据的

盘片在主轴上是彼此对齐的

因此，在不同表面上，轨道也是对齐的

比如这条轨道，这些轨道的集合

这些轨道的集合，我们称之为一个柱面，因为它形成一个圆柱形

磁盘的容量就是它可以存储的位数

所有供应商都以千兆字节（GB）为单位来表达磁盘容量

这里的 1GB 是 10^9 字节而不是你所想的 2^20 字节

我也不确定他们为什么这样做......

不过，允许以 10^9 字节作为容量的单位

这是一个更大的数字对吧

所以看起来好像可以存储更多的信息

我不知道他们为什么这样做，但我认为可能原因就是那样的

有点烦人，所以我们需要了解，然后习惯这个设定

磁盘的容量是由两个独立的因素所决定的

第一是记录密度，决定单独一个扇区可以存储多少比特

或者至少是一个磁道的一部分

然后是磁道密度，指可以将相邻的磁道放置得多临近

这两者的乘积，称为面密度，决定了整个磁盘的存储容量

面密度越高，你就在一个磁面上可以存储越多的比特

在以前，磁盘的面密度相当低

磁面上每一个磁道所包含的扇区数量是相等的

每一个磁道所包含的扇区数是一个常数

现在会有一种情况

磁道有比较靠近中心也有较为边缘的

如果磁道是由相同比特密度的扇区组成

那么越往外，扇区间的间隙会越变越大

你将会浪费越来越多的磁面上的空间

不过如果面密度比较低的时候这还是可以接受的

但随着技术发展，浪费空间就不太能被接受了

现代的系统为此所做的改进是

将磁道划分为所谓的记录区

这里的每一个记录区，如图所示

每一个记录区包含相同数量的扇区

所以一个记录区里的每一条磁道都有相同数量的扇区

当然，对于越靠外的记录区

将扇区之间的空隙会越来越大

但是在这里看这个新的记录区

它的每一条磁道里会有更多的扇区

你可以发现，在靠外的磁道，会比靠内的磁道有着更多的扇区

你可以发现，在靠外的磁道，会比靠内的磁道有着更多的扇区

这就是处理扇区之间的间隙变得过大的方法

因为采用了此技术，每一条磁道所包含的扇区数不再是一个常数

于是我们使用平均值，也就是每条磁道平均包含的扇区数

用所有记录区的平均每条磁道扇区数来估计整个磁盘的容量

好的，你可以想象计算磁盘容量的公式是相当简单的

它是每个扇区的字节数

乘以每个磁道上的平均扇区数

再乘以每个盘面的平均磁道数，再乘以一个盘片的盘面数

最后在乘以磁盘中盘片的数量

现在让我们来看看它是如何工作的

这些表面都以一个固定的频率在旋转

现在典型的速率可能是 7200 转/分钟，这是相当常见的转速

如你所见磁盘是这样旋转的，我还（对这个PPT）挺自豪的

像这样逆时针旋转，然后，磁臂

磁臂沿着半径轴前后移动

磁臂沿着半径轴前后移动，可以定位到任何一个磁道上

好的这部分讲到这里

好，现在考虑多个盘片的情况

每一个盘片都有磁臂，实际上都有多个臂，每个表面上都有一个读/写头

所以一个盘片有两个（磁头），上面下面各一个

涂上这种磁性材料

会在每一侧都有一个读/写头

然后这些都是连接在一起的，一起移动

现在，原始的这种读/写头将是很死板的

因为那时候的磁道密度没有那么高

所以即使磁道没有很好地对齐

它们还是可以全部覆盖

读/写磁头仍然可以用这种固定的磁臂覆盖所有磁道

但现如今，磁道密度如此之高

实际上控制器实际上可以移动读/写头一点点

这样它就匹配了所有表面上的所有轨道

好的，一起来看一下我们读取数据的方式

首先，我们有

这是我们的这是我们的磁臂，箭头的尖端是读/写头

并且它被定位并且盘片逆时针旋转

读写头当前的位置正好可以读这个蓝色的扇区

当蓝色扇区在读/写头下旋转

它会检测这些比特，并将它们发送到控制器，控制器将它们传递回CPU

现在，CPU请求磁盘

它要求磁盘读写红色扇区的数据

所以，控制器需要操控读/写头

先将其移回红色扇区所在的磁道

然后等待磁盘旋转

等到该扇区旋转到读写头的下方

然后读取红色扇区中的数据

所以这里一共有三个因素

决定着阅读其中一个扇区需要多长时间

移动磁头的时间称为寻道时间

我们等待磁盘旋转，等红色扇区旋转到读写头下方

这部分称为旋转延迟，它通常有多长时间呢

平均情况下就是磁盘旋转一整圈所花费的时间的一半

平均情况下就是磁盘旋转一整圈所花费的时间的一半

最后一个因素是传送时间，是指

是指该轨道在读/写头下通过的时间

是指该轨道在读/写头下通过的时间

知道这些的重要原因是

这三个因素，将它们加在一起，这就是你的平均值

磁盘访问数据的平均时间

磁盘访问数据的时间主要是寻道时间

所以寻找时间是以毫秒为单位测量的。寻道就是把磁头移到那里

这是一个伺服系统，是实际的机械运动

这就要花时间

它大约在 3 到 9 毫秒之间，这已经存在了几十年

这个值是改不了的

这是一种基本的机械限制

这使得降低这个值非常困难

下面谈谈旋转延迟

旋转所需的时间我们称之为 Tavg rotation（平均旋转时间）

然后，磁头读取这些比特所需的时间称为 Tavg transfer（平均传输时间）

好的，所以我们的搜索时间包含三个部分，即寻道时间、旋转延迟和传输时间

现在，我们取一些真正的数字来做一些运算

你看，我们的寻道时间是毫秒级

旋转延迟也是毫秒级

有机械限制，限制了你可以用多快的速度旋转它们

传输时间是非常短的

所以它的数量级要小一些，因为你只需要读扇区中的一些位

好的，你可以看到总访问时间主要是寻道时间和旋转延迟

所以这儿有一个好的经验法则，用于估计从磁盘读取数据所需的时间

就是两倍的寻道时间，就很精准了

基本上传输时间可以忽略不计的

现在，这里要讲一些有关于磁盘的重要信息

访问 SRAM 取得一个 double 类型的双字，时间大约为 4 纳秒

在 DRAM 上大约是 60 纳秒

所以 DRAM 比 SRAM 慢一个数量级

但是磁盘比 SRAM 慢 40,000 倍

这就是 4,000 倍的差异

这个时间差是非常巨大的，它比 DRAM 慢 250 倍

所以 DRAM 和 SRAM 之间存在很大差距

磁盘和其他内存类型之间存在更大的差距

现在，现代磁盘呈现出更简单的视图

我们这里学到的磁道、柱面、扇区等几何描述

实际上现代磁盘控制器

是将磁盘作为一系列逻辑块提供给 CPU

每个块是扇区大小的整数倍

所以在最简单的情况下，块只是一个逻辑块就是一个扇区

块从零开始编号

块号是一系列增长的数字

然后磁盘控制器保持映射保持物理扇区和逻辑块之间的映射

然后磁盘控制器保持映射保持物理扇区和逻辑块之间的映射

计算机科学中古老的有趣的智慧就是涉及某种形式的间接

所以这是一个间接层面

让你了解逻辑块和物理块之间的映射

它允许磁盘控制器将一些柱面保留为备用柱面

这些柱面没有被映射为逻辑块

如果有个柱面的一个扇区坏了

磁盘控制器可以将数据复制到备用柱面，然后磁盘就可以继续正常工作

这就是为什么磁盘的“格式容量”会比实际容量要小，如果你去数实际的柱面数的话

“格式容量”会比实际容量要小

因为其中一些柱面是为故障处理而预留的

现在，像磁盘这样的设备连接到 CPU 和内存

通过 I/O 桥，通过另一种称为 I/O 总线的总线

我现在向你展示的内容实际上并不代表现代系统就是这么简单的

它代表了大约五年前所谓的 PCI 总线

现代总线是……PCI 总线是广播总线，这意味着它只是单一线路

因此，如果这根总线上的任何设备更改了某个值

该总线上的每个设备都可以看到这些值

好的，它被称为广播总线，它是将事物连接在一起的最简单的方式

现代系统使用称为 PCI Express 的总线结构

虽然它有 PCI 这个词，但它是完全不同的，它是点对点的

因此，设备通过一组点对点连接进行连接

通过某种开关仲裁

我们不会深入探究其细节，它是一个更有效的设计

它更快，但它提供相同的功能，

它允许你将所有设备连接到 CPU

因此，只需将此总线视为一组电子线路即可

每根电线都带有一个比特的信息

并且连接在总线上的每个设备都可以看到所有电线上的所有值

有一些设备是直接焊接在主板上的，直接连接到总线上

磁盘是直接插入主板上的插槽

还有诸如图形适配器和 USB 控制器

然后系统提供一个接口

因此，你可以将鼠标和键盘等插入 USB 控制器

然后还有扩展插槽

允许你添加其他设备，将其连接到总线上

例如你想在那里放一个网络适配器

当我们想要读取磁盘扇区时会发生什么

那么 CPU 通过编写三元组来启动此读取行为

所以它写了三个不同的值。首先是写了个指令，比如说 read

它还写入一个逻辑块号

是我想读取的那个逻辑块的块号

然后我想将该逻辑块的内容放在内存中的某个地址

好的，三要素就是指令、逻辑块号和内存地址

磁盘控制器读取与该逻辑块对应的任何扇区

所以我们假设一个逻辑块由一个扇区组成

然后它做了这个有趣的事情，它取得总线的控制权

它现在复制数据，这是磁盘控制器

通过 I/O 桥将数据复制到 I/O 总线，直接复制到主存储器，而无需通知 CPU

所以 CPU 完全忘记了这种传输正在进行的事实

然后，一旦它将数据传输到主存储器

然后它使用这种称为中断的机制来通知 CPU

所以它实际上 CPU 芯片本身上用了一个引脚

它将该引脚的值从 0 更改为 1

该触发器是一个中断，它通知 CPU，该扇区已被复制

好的，对于 CPU 来说，现在某处有某个程序正在等待，将数据读入内存

所以现在 CPU 可以执行该程序并处理该内存

那么这个机制有什么好处？

他们这样做的原因是因为从磁盘读取数据实在是太慢了

在 10 毫秒内，系统可以执行数百万条指令

CPU可能正在执行数百万条指令

如果要让 CPU 停下来，等待从磁盘上读取数据完毕，那将是一个可怕的浪费

这个机制做的事情就是它将此请求发送给磁盘控制器

然后，虽然那个非常缓慢的磁盘读取过程正在进行

但 CPU 可以同时执行其他指令，执行其他有用的工作

所以这对于获得合理的性能非常重要

防止这个非常慢的磁盘系统减慢整个系统速度

现在有另一个有趣的很火热的类型的磁盘称为固态磁盘

大概是旋转磁盘与 DRAM 存储器的中间点

在 CPU 看来，一个固态磁盘

它看起来与旋转磁盘完全相同，它具有相同的接口

它具有相同的物理接口，具有相同的包装

在 CPU 看来就好像是一个旋转磁盘

但它没有所有这些机械部件，而是完全由闪存构建

和充当控制器的固件

因此，在固态磁盘内部有一组固件，称为闪存翻译层

其作用与旋转磁盘的磁盘控制器相同

然后内存本身......

可以以页为单位从闪存读取和写入数据

页的大小取决于技术的不同，可以是 512 千字节到 4 千字节

然后一系列的页形成一个块

这里提到的块与 CPU 所认为的逻辑块是不同的

所以这是一个不幸的术语重叠

但这里有个诀窍是，我猜这里的限制是在固态硬盘中，数据是以页为单位写入的

一个页只能在所属的整个块都被擦除之后，才能写这一页

好的，这似乎有点奇怪，但这就是它的工作方式

那么这意味着你想要对固态硬盘进行写入

如果你想写一个页，你必须找到一个被擦除的块

你必须将目标块中的所有其他页面复制到该新块，才能正确执行

好的，你可以看到现在写操作变得相当复杂。读操作没改变，你还是可以读任何东西

然后像所有闪存一样，这是一种有效的机制，因为，你正在写一页

但要做到这一点，你必须复制该块中的其他所有页面，你必须擦除整体

然后当你完成后，你擦除这个块，以便它可以用于其他写入

所以最终在经过十万次重复写入后，这个块就会磨损

现代系统的闪存翻译层

实现了各种花里胡哨的专有算法，以延长 SSD 的使用生命，例如缓存技术

并且还有各种技巧来延长这些 SSD 的使用寿命

所以在实践中，这不是一个大问题。我接下来就会展示

下面介绍 SSD 的性能特点

现在你可以想到一个典型的硬盘，它的读写速度大概

你知道我的意思，是指去测量磁盘驱动器（的读写速度）

可能是每秒 40 或 50 MB，这是一个典型的速度

而 SSD 的速度要快 10 倍

因此对于顺序读取，你可以获得大约 550MB/s 的速度

顺序写入有点慢

如果是随机访问，无论是读或写都比顺序访问慢一点

而且我们会看到这是相当普遍的

就是在内存系统中，按顺序执行操作几乎总是比在内存中跳来跳去更好

随机写入速度较慢，是因为擦除的存在，擦除需要大约一毫秒的时间

所以现在我们又回到那个毫秒级的范围，这就很慢了

正如我所提到的那样，如果你修改某一页，该页所在块中的所有其他页都必须被复制

早期的 SSD 在随机写入和顺序读取的速度存在巨大差距

但因为闪存翻译层的改进，这一差距有所缩小

读写操作肯定存在时间差异的，写入更慢，对吧？

但他们正在做各种有趣的的改进，以使这些数字相当接近

好吧，当我们有了 SSD 模型，我们真的不需要再区分读和写

因为 SSD 没有移动的部件

所以它们的读写速度非常快，消耗的电能也少，同时也更结实

这就是为什么 SSD 用在 U 盘中是有好处的

像是 IPods 和类似的东西

但它们有可能磨损

这可能是一个问题，但实际情况也不是大问题

英特尔保证，在对于他们的产品，在损毁之前，你可以执行 128 PB 的写入

英特尔保证，在对于他们的产品，在损毁之前，你可以执行 128 PB 的写入

那是很大量的数，我的意思是考虑一下要写那么多的数据够你写多少年了

截至目前，2015年

SSD 存储每个字节的价格比旋转磁盘贵很多

所以旋转磁盘的容量要大得多，但速度更慢一些

SSD 更小更快

现在，如果你看一下

如果你看一下这些不同存储设备相对于 CPU 的性能特征

随着时间的推移，你会得到这个非常有趣的图表

此图的 y 轴标识访存所需要的时间，单位为纳秒，以 10 的指数为尺度

好的，y 轴上相邻一格的变化，都表示访问时间的一个数量级差异

在 x 轴上，我绘制了从 1985 年到 2015 年的时间

然后我绘制了各种设备访存需要花费的时间或 CPU 周期时间

绘制了硬盘、SSD、DRAN 和 SRAM 访存的时间

和一个 CPU 周期的时间

让我们先看图表的下方，是 CPU 周期的时间随着历史的发展的变化

你所看到的是一个 CPU 周期的时间从 1985 年到 2003 年以这种指数速度在下降

基本上每 18 个月或两年，时钟频率就会加倍，结果是

大约过 18 个月到两年，一个 CPU 周期的时间会减半

所以这就是制造商在 2003 年之前所做的事情

为了使他们的处理器更快，他们只会使时钟频率加倍

它们减小了它们制造的芯片的特征尺寸

这可以让制造商把更多的部件放的更紧密

然后按比例增加时钟频率

现在这一切都在 2003 年结束，这是计算机历史上有趣的一年

因为有一种不幸的特性，就是 CPU 消耗的电能

与其时钟频率成正比

CPU 越强，其时钟频率越高，消耗的功率越大

到 2003 年，英特尔准备新出品的处理器将耗费大约 800 瓦的功率

想象一下，你的笔记本电脑里面有一个 800 瓦的灯泡（笑

我实际上看到了其中一个设备的早期原型

吸收芯片热量的散热器大约是四平方英寸大

这在主板上简直是一个庞然大物

所以这就是我们所说的处理器设计在 2003 年触及了能源的瓶颈

他们再也不能继续增加时钟频率

为了制作更快的计算机

那么他们在 2003 年之后必须做些什么

而不是增加时钟频率，尝试设置加倍时钟频率

他们在芯片上放置了更多处理器内核

所以现在他们将 CPU 芯片细分为单独的处理器内核

每个核心都可以执行自己的指令

然后通过并行运行

CPU 可以更有效地工作，因此有效的周期时间可能会继续下降

所以我在底部绘制的是有效循环时间

换言之，是循环时间除以核心数

所以在 2005 年，出现了第一个使用两个核心的系统

所以你可以运行两个独立的线程或两个独立的程序

当前，它发展到了四核服务器级系统，你可以获得八个核心

甚至还有 12 核芯片

因此，未来的趋势将会是时钟频率将保持相当的稳定

你可以看到 CPU 周期时间

它们实际上在这里增加了一点，然后它们慢慢地下降，但是通常是平的

所以真正获得更多性能的唯一途径

是增加独立核心的数量

这就是它的方式

现在，看第二行的黑色圆圈中，我绘制了 SRAM 访问时间的发展过程

你可以看到 SRAM 的情况和 CPU 跟踪地非常好

虽然它的速度要慢一些些

它很好地跟上了 CPU 性能的发展

至于 DRAM，你可以看到 CPU 和 DRAM 之间存在几个数量级的巨大差距

在过去的几年里，DRAM 已经变得更好了

但也已经证明非常难以更快地速度进步了

SSD 介于磁盘和 DRAM 之间

然后看这里的磁盘的曲线，你可以看到一百万纳秒，就是毫秒级别

你可以看到磁盘的访问时间在毫秒范围

曲线下降了一点点，但还是不怎么够

所以我想说的是 DRAM、SSD、磁盘和 CPU 之间存在着访问时间的巨大差距

而且在某些情况下，随着时间的推移，它甚至会变得越来越糟，因此这是一个问题

我们的程序都需要数据，我们的数据存储在内存和磁盘中

所以如果你的计算机变得越来越快

我们的存储设备的访问速度却保持相对不变，甚至变得相对较慢

然后我们就遇到了一个问题，就是我们的计算机性能实际上不会增加

很难让我们的程序运行得更快

因为我们会受到访问数据所需时间的限制

好的，这就是我们必须处理的基本问题

事实证明，弥合 CPU 和内存之间差距的关键

是这个非常根本的程序的基本属性——程序的局部性

好的，这是程序的一个基本的，持久的属性

所以我们说，程序有这个属性，叫做局部性

这意味着什么......

对不起，在我给你们讲之前我只需要读一读，因为它是非常准确的定义

因此，程序倾向于使用其地址接近或等于最近使用过的数据和指令的那些数据和地址

好的，如果程序访问是一个数据项，那么

它将在不久的将来的某个时间访问该数据项或附近的数据项的可能性非常高

在不久的将来，该程序可能会访问该数据项或附近的数据项

这个属性称为局部性

通常，局部性有两种不同的形式

时间局部性是最近引用的存储器位置可能在不久的将来再次被引用的属性

例如，你读取了一个变量

你有可能再次阅读该变量

例如，假设你在循环内，不断累加结果到一个变量

那循环中的每一次迭代都会访问那个变量，对吧

空间局部性是指引用临近存储器位置的倾向

如果我们访问了一个存储器位置，那么有很高的可能性我们在将来会访问一个临近位置

让我们看看这段代码，看看我们是否可以在此代码中识别出所有不同类型的局部性

所以我们有两种不同类型引用，首先是数据的引用

然后是对数据的引用，所以我们正在读取内存中的指令

这些指令再引用数据

首先要注意的是，我们在引用的数组里的元素是连续的

所以我们每次对变量 i 增加 1

循环的每一次迭代都自增变量 i，然后读取 a[i]

好的，所以这被称为步长为 1 的引用模式

步长是指我们将这个索引递增多少

因为我们这里的变量i每次递增 1，所以是步长为 1 的引用模式

对于 a[i] 的这些重复引用，是属于哪一种程序的局部性？空间局部性还是时间局部性？

是空间局部性，对吧？因为我们正在访问附近的存储器地址

好的，那对于在循环内部，不断引用 sum 这个变量

就体现了程序的时间局部性

那现在来考虑一下指令

循环中的每一次迭代，我们引用的都是一系列（相同的）指令

这体现了哪一种程序局部性原理？

在每个循环迭代中？是空间局部性对吧？

因为我们只是在每次循环迭代中执行一系列（相同的）指令

但是我们反复地执行这个循环

因此，在每次循环迭代，我们很有可能将访问那些指令

每次迭代都访问上一次迭代访问过的指令

随着程序进行，我们只是执行相同的指令

执行的是相同的，实现此循环体的汇编语言指令

现在在这个简单的例子中，它可能就是一条指令

但一般来说，你的循环可以有多个指令

现在，现在我想对你们说的就是这整个课程的主要观点之一

作为一个专业的程序员

这是一项必不可少的技能，你观看代码，就可以获得对其局部性的定性认识

因为我们会看到，好的程序局部性带来良好的性能

这就是如今系统的构建方式

因此，作为一名程序员，能够在看到代码时获得一些定性感觉对你来说非常重要

就像，你可以分析出来，代码的这部分局部性非常好，这部分局部性非常差，

你需要做的是避免代码出现差的局部性

那么让我们看一个简单的例子吧

一起看看我用这个例子想表达什么意思

所以我正在做的是我有一个二维数组 a

数组 a 有 m 行和 n 列

并且在双重嵌套循环中，用索引 i 和 j 来迭代

我正在求该二维数组的所有元素的总和

好吧，这似乎是一个非常简单的操作，怎么可能出错呢？

实际上，如果你以使其具有较差的局部性的方式编写此代码， 则它将以慢一个数量级的速度运行

好吧，看看这段代码，你认为这段代码的局部性是好的还是差的？

让我们看一下关于对数组 a 的访问

是好是坏 ？

数组 a 在内存中是如何布局的呢？

是行优先的，对吧？数组是以行优先顺序来存储的

首先是第一行的所有元素

然后跟着第二行的所有元素，之后是第三行的所有元素

好的，我们如何访问这个数组

看看我们正在访问 a[i][j]，我们正在以最快的速度改变 j

所以我们保持 i 不变，然后我们改变 j

然后我们访问所有这一行的元素，所以我们保持 i 不变来访问第 i 行

然后我们改变 j 来访问该行中的所有列

好的，然后我们回去增加 i

所以现在我们正在访问下一行

好的，如果我们查看 a[i][j] 的地址，查看正在被读取的地址的序列

这个序列符合于步长为 1 的引用模式，因此我们将依次按顺序访问所有元素

好吧，这是非常好的空间局部性，这是你能做到的最好

现在，对于变量 sum 来说，有很好的时间局部性，所以这是好的

对，所以这个程序的局部性都很好，所以这是好的情况

那这个呢，我将上一个相同的程序

我只是颠倒了循环的顺序，它首先在 j 上循环，然后在 i 上循环

然后内部循环体是相同的

现在，这对我们访存的空间局部性有了什么影响呢？

学生：非常糟糕的空间局部性

非常糟糕！对，你看到这段代码的时候应该觉得被冒犯了，简直糟糕透了

很糟糕，对吧？因为看起来

所以我们现在做的事情就是

我们保持 j 不变，然后我们遍历每一行的第 j 个元素，这是在内存中跳跃

我们在每行中都有 n 个元素，因此我们是以步长为 n 的模式来对内存进行访问

所以我们就像是这样

访问一个数，然后将列递增 1，然后我们再次这样做（步长为 n 的访问模式）

所以这是一个糟糕的空间局部性，这是我们可以获得的最差的空间局部性

现在让我们来看一个三维数组

我现在提出以下问题

你能否基于这种定性观念

这个观念是你最好需要尝试使用步长为 1 的访问模式

给出这个循环体，你要怎么置换

a[k][i][j]，你要如何置换循环的顺序，使它满足步长为 1 的引用模式

好吧，这是正确的，循环的先后次序应该是 k、i、j

所以通常我们想做的是要从右到左

我们希望右边的这些索引变化是最快的

我们希望 k 和 i 保持不变，然后我们想先要改变 j

然后再增加 i，然后再增加 k

我们想要按照顺序来访问所有的 j 值

好的

好的，我们已经研究了一些存储技术的技术属性

我们得到了这种基本原则，即更便宜的存储设备……

……存储容量越大的存储设备，越便宜

更昂贵的存储设备，其存储空间会设计得更小

因为我们不能花太多的钱

我们的存储设备和 CPU 之间存在这种访问速度的差距

至少在磁盘容量变得越来越大的情况下

但好在，程序具有局部性这个原理

好的，这三件事，即存储技术的这些特性

和我们的程序的局部性属性

相互补充得非常完美，为人们提供一种设计怎样存储系统的建议和信息

这种设计被称为存储器层次结构

好的，这是就是存储器层次结构的概念

你将内存系统分层设计，而不是单一的平层

将存储器系统设计为存储设备的层次结构

在这个层次结构的顶部

你拥有存储容量较小，访问速度更快，但也更昂贵的存储设备

所以在最顶层的是寄存器

寄存器在每一个 CPU 周期，每执行一条指令都可以被访问

指令执行期间可以读写寄存器

所以寄存器是位于存储器层次结构的顶部

但由于这些都是定制芯片，因此它们非常昂贵

生产处理器的制造工厂耗资数十亿美元

好的，所以这是最贵的

因为它的容量也是最小的，我们在层次结构的顶部只有 16 个寄存器

在接下来一层是一个或多个 SRAM，SRAM 是更快的一种内存

SRAM 是更快的一种内存

我们设置一个或多个所谓的高速缓存存储器，是使用 SRAM 制作的

这也是在处理器芯片内部的

这些缓存，因为它们是由 SRAM 制成的，它们的大小是兆字节（单位为 MB）

它们比寄存器大得多，但它们也只是兆字节这么大

再接下来一层就是

再接下来一层就是 DRAM 所做的主存，主存在现代系统中可以有十几个 GB 的大小

再接下来一层就是磁盘

我们甚至可以把像网络服务器这样的东西认为是更低的一层，例如在谷歌上存储的东西

你可以将其视为我们存储器层次结构的一部分

现在要介绍一个这里是关键点，在存储器层次结构中

存储器层次结构中的每一层都包含从下一个较低级别层次所检索的数据

好的，CPU 寄存器保存着从 L1 高速缓存中取出的数据

L1 高速缓存保存从 L2 高速缓存中检索的数据

L3 高速缓存从主存从取出数据，主存又保存着从磁盘取得的数据，依此类推

内存系统设计如此的原因

当你拥有这种系统时

一般来说，在层次结构的顶部，你可以以最快的方式来访问内存

一般来说，在层次结构的顶部，你可以以最快的方式来访问内存

所以这是最快的

但是在层次结构的较低层，访问速度较慢

好的，所以这一切都有效，因为一个叫做缓存的想法

所以缓存对计算机科学家来说

它是一个更小的更快的存储设备，充当更慢的设备中的数据的暂存区域

所以就像在这里一样，你可以把你的主存认为是存储在磁盘上的数据的缓存

你从磁盘读取数据，然后将其存储在主存中

对吧，你可以把主存储器想象成一个临时区域

一旦从磁盘获取数据，就不会再在磁盘上访问它，而是在内存中访问它，速度要快得多

好的，这个想法一直在层次结构中传播

好的，我们可以这么想象缓存

可以通过想象你的背包来比喻缓存，当你早上要来上学的时候

比如你的公寓离学校有点远

所以在你上学之前，你要带一些东西

你把它们放在你的背包里

你背着包来上学，然后如果你需要用到那些东西你就从背包中拿出来

如果你不这样做

每次你需要用到某样东西，你都必须走回家拿，然后再带回学校

好吧所以这就是缓存的概念，你知道它是一种非常熟悉的简单概念

但事实证明它非常强大，并且它出现在计算机系统的所有部分中

对于存储器层次结构中的每一层，我们现在设为第 k 层

第 k 层的，更快更小的存储设备，都是缓存

都是对于第 k + 1 级较大较慢的存储设备的缓存

要记住，体系的层次中从 L0 开始是最高的

所以这个最小的数字实际上是最高的级别

层次结构中每进一步，我们提高级别

在层次结构中不断深入

现在他们为什么这么做，所以这是一个非常基本的想法

这个结构之所以有效就是由于程序的局部性原理

由于局部性原理，程序倾向于访问存储在第 k 层的数据

比访问第 k + 1 级的数据更常见

好的，如果我们访问第 k + 1 层存储单元

我们会将其拷贝到第 k 层，因为我们很有可能将再次访问它

好的，现在我们以第 k 层的设备访问速度，多次访问第 k 层的数据

而不是以第 k + 1 层的速度

这就是这个层次结构概念的有趣之处

而且因为我们不经常访问第 k + 1 层的数据

我们可以负担得起使用更便宜的速度较慢的存储设备

在这方面，因此我们可以使它们容量更大，存储每比特的价格更便宜

层次结构创建了一个大型存储池

其存储容量大小大约等于最底层存储设备的大小

却可以以最高层存储设备的速度来访问

好吧让我们来看看缓存的一般方式工作

然后我们将在星期四学习其中的细节

但就像我说的，缓存是一个非常通用的概念，可以应用于存储器层次结构中的所有层

所以这里我们有一个缓存，在各种缓存中都有某种传输单元

在层级之间来回拷贝

所以我们在上层有这个

我们有一个称之为可以容纳四个块的缓存

我们又有在底层的内存

并且这个内存被划分为一些固定大小的块

这就是接近存储器层次结构上层的缓存的工作方式

若处于较低级别，就像你从 Web 服务器访问数据一样

在这个例子中，通常将数据划分为文件

但它的上层数据被分区为块，所以假设这是主存

然后，在这之上，有由一堆这些块组成的（高速缓存）

所以我们只需将内存分成一个个的块，每个块的字节数相同

然后，数据将以块大小为传输单位在内存和高速缓存之间传输

如果你需要来自内存的数据，如果告诉缓存需要来自主存的数据，那么它将获取整个块

然后在任何时间点，高速缓存都保存主存储器中块的一个子集

好的，所以这个缓存要快得多，但速度也慢得多（口误，应该是容量更小）

因此，它的存储容量要小得多......

抱歉，它的速度要快得多，但它的价格却要贵得多

而且因为它更贵，所以它存储容量更小

现在假设缓存要引用某个内存块，假设 CPU 现在要求第 4 块中包含的数据

CPU 首先查看这个数据是否存在于高速缓存中

（第 4 块不存在于高速缓存中）所以缓存要求主存给它第 4 块

这样这个块就会从内存复制到缓存中

覆盖缓存其中一个现有的块 8

所以现在块 4 存在于我们的缓存中

现在假设 CPU 请求第 10 块中的一些数据

这样第 10 块会被复制，又覆盖掉缓存中的那个（第 14）块

现在将块复制到缓存中的想法是，我们希望在 CPU 上执行的程序

将重用我们复制到高速缓存中的一个块

我们费力地从内存复制块到缓存，我们知道这很慢

所以现在假设 CPU 需要块 b 中的一些数据，在这个例子下是块号为 14 的块

好吧所以它需要存储第 14 块中的一个字

现在缓存内有这个块，因此可以直接返回，我们称之为缓存命中（cache hit）

我们要访问的块正位于缓存中，这叫缓存命中，这是很好的

因为现在我们可以将该块直接返回给CPU

而且使用高速缓存的访问速度比如果要去访问 DRAM 主存要快得多

SRAM 比 DRAM 快得多

相比要到主存中去取得这个块，通过这种方式 CPU 非常迅速地取得第 14 个块

相比要到主存中去取得这个块，通过这种方式 CPU 非常迅速地取得第 14 个块

好吧，与缓存命中刚好相反的是缓存不命中（cache miss）

假设 CPU 现在请求第 12 块

在高速缓存中查无此块

这就是缓存不命中，高速缓存需要从主存中取出第 12 块

复制第 12 块到高速缓存中，然后可以返回给 CPU

所以这需要更长的时间，因此 CPU 必须等待高速缓存从内存中取出该块

所以一旦出现缓存不命中，访问速度就会很慢。所以缓存命中很好，因为很快

缓存不命中很糟糕，因为会很慢

我们通常区分几种不同的缓存不命中的种类

因此，第一种是冷不命中（cold miss）或强制不命中（compulsory miss）

这是因为高速缓存中没有任何的数据

最初缓存它们是空的，没有存储任何块，当我们要读取数据时

当我们要读取数据时就要从下一级获取块，将它们放入缓存中

缓存将慢慢填满

也就增加了缓存命中的可能性

但是当缓存为空时，每一次访存都肯定会缓存不命中，对吧？

所以没有办法避免冷不命中

将数据项加载到空的缓存中，这称为缓存的暖身

最初缓存是空的，当往里添加越多的数据块，热身意味着增加了缓存命中的可能性

还有一种与冷不命中对应的情况，称为容量不命中（capacity miss）

容量不命中的原因是高速缓存的大小是有限的，你不能（容纳超过缓存大小的工作集）

在我们看到的例子中，我们的高速缓存只有四个块的大小

如果我们的程序的局部性需要用到包含 8 个块的数据

假设我们正在循环访问数组中的元素，这个数组包含 8 个块的数据，

那么自然容量仅有 4 个块的高速缓存无法放下整个 8 个块的数组

因此，我们将会遇到容量不命中，我们需要更大的缓存才能存储这 8 个块

如果我们有足够大的缓存，那么就会有良好的命中率

如果我们可以在缓存中存储所有块，然后缓存可以利用该程序中的空间和时间局部性

所以一般来说，在程序运行的任何时候，

我们将这一些不断被程序访问的块称之为工作集（working set）

工作集是会改变的，当你的程序从一个循环执行到另一个循环，从一个函数到另一个函数时

但是在程序执行中的某个时间点

有一个工作集的概念，它就是你需要存储在缓存中的块

好的，所以当你的工作集大小超过你的缓存大小时，就会发生容量不命中

还有另一种奇怪的缓存不命中，称为冲突未命中

这与缓存的实现方式有关

这里的概念是，大多数缓存，特别是硬件缓存，因为它们必须设计地较为简单

限制了块可以被放置的位置

块可以被放在缓存中的一小组位置

像最简单的模型之一就是

块号为 i 的第 i 块只能放在（i mod 缓存大小）处

所以假设我们有一个缓存，可以容纳四个块

当我们从主存中读取一个块号为 i 的块时，会将其放到缓存中的（i mod 4）处

所以主存中取出的块 0 将存在我们的缓存中的块 0 处

第 4、第 8 块都会放在 cache 中的第 0 块，第 9 块将放在 cache 中的第 1 块

假设我们使用该模型，当发生这种情况时

对于块号为 i 的块，我们只能将其放在 cache 中的（i mod 4）处

对于块号为 i 的块，我们只能将其放在 cache 中的（i mod 4）处

假设我们从主存中要引用的数据对象是块 0、块 4、块 8

只引用三个块，所以我们在缓存中有足够的空间来存储这三个区块

但由于映射缓存块的方式，每一次拷贝新的块到 cache 时都会导致驱逐另一个块

当我们访问第 4 块时，它将进入高速缓存中第 0 块已经占有的位置

当我们在高速缓存中访问第 4 块时

它会覆盖第 0 块所在的位置

因此，这种访问模式与用于映射块的算法密切相关

因此，这种访问模式与用于映射块的算法密切相关

因此，即使我们有足够大的缓存

但由于这种访问模式和映射算法

缓存会一直不命中

我们将在明天研究 cache 中冲突不命中的细节

所以

所以这就是缓存存在于存储器层次结构中的任何地方的体现

所以它们都是各种形式的缓存

你可以将寄存器视为一种缓存

它们缓存的是八个字节的字

好吧，它被缓存于何处？在 CPU 上

延迟呢？没有延迟，发送在一条指令的执行周期内

然后是谁管理缓存？必须要有东西管理缓存

当有请求从层次结构中的较低层读取内容时

必须有一个过程决定如何处理这个请求， 如何将其放入的缓存中的某一位置，我们称之为缓存管理

在这种情况下，由编译器管理缓存

当你编译 C 语言代码时，编译器会确定由哪个寄存器

编译器会确定由哪个寄存器来存储来自内存的数据项

TLB（翻译后备缓冲，Translation Lookaside Buffer）      是一个在虚拟内存中使用的缓存

然后是这些称为 L1 和 L2 缓存的硬件缓存

它们在现代英特尔系统上存储 64 字节块

它们被缓存于 CPU 芯片上，由 SRAM 制成，集成在 CPU 上

L1 缓存在酷睿 i7 上的延迟是 4 个时钟周期

L2 缓存的延迟是 10 个 CPU 周期

这两者都是由硬件管理的

所以，当 CPU 要从 L1 缓存中读取一个内容时，由硬件来管理

如果出现了未命中，就会从 L2 缓存中加载一个块，L1 缓存中的硬件来决定在哪里存放这个块

好的，所有这些都是在没有硬件干预的情况下完成的

磁盘包含由操作系统维护的缓冲区缓存

在这种情况下，缓存的是文件的一部分

好的，他们被缓存在主存中

缓存到主存的延迟大约一百个时钟周期左右

这些都是由操作系统管理的

因此，操作系统会保留一部分内存来存储你已加载的文件

因此，如果你读取文件，操作系统将利用本地性

然后开始从该文件中读取字节，它实际上将从主存中的文件缓存被读取

而不是去磁盘上读取

网络也维护着一份本地地盘的缓存，例如网络文件系统（Network File System）和安德鲁文件系统（Andrew File System）

浏览器有缓存机制，因此从服务器获取文件时

浏览器将会把这些文件本地存储在磁盘上，以便再次引用这些网页

然后这些文件就会从你的本地磁盘读取，而不是一直通过网络重新请求

好的，这里的理念就是，缓存机制存在于存储器层次结构中的任何位置

而且它们都基于相同的原则，它们只是以不同的方式来实现

好的，现在总结一下我们今天所学的东西

我们学习了 CPU 和存储器设备之间存在着访问速度的巨大差距，而且在不断扩大

我们学习了编写良好的程序具有称为程序性的属性

我们了解了缓存的概念

利用缓存的概念和程序的局部性原理，我们可以构建存储器层次结构

允许我们构建存储系统，以便我们以最快的设备速率访问数据

但却有着底层设备容量大，造价低廉的优点

好的，星期四我们将具体学习存储器层次结构的一个非常具体的部分，高速缓存存储器
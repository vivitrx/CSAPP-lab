大家下午好，欢迎来到 213 课程教室，很高兴我们又见面了

提醒你们一下，attack lab 将于今晚 11 点 59 分截止

这个 lab 你将有一个宽限期

我们将在同一时间发布 cache lab

cache lab 的时间有点紧张，它将在下周四截止

所以希望你们能够抓紧时间开始

上节课，我们学习了「内存层次结构」以及「缓存」的概念

今天我们将介绍一个重要概念「缓存」

它被称之为「高速缓存存储器」

作为程序员，它们对你非常重要

因为它们会对程序的性能产生巨大的影响

如果你知道这些缓存的存在，而且你了解它们是如何工作的

作为程序员的你，就能够在程序中发挥它的优势

上次，我们说到内存层次结构是存储设备的集合

越处于顶部的存储设备容量越小，越昂贵，速度也越快，处于底部设备则相反

这个层次结构的每个级别

层次 k 的存储设备作为高速缓存，储存着下一层次中的一部分子集

即层次 k + 1 的存储设备的子集

回想一下缓存的一般概念，假设我们有一块内存

它实际上是由字节「byte」组成的数组，但我们把他拆分视作为 「块」 的集合

这些内存更大、更慢、更便宜

它比一个更小，更快，更昂贵的缓存的容量要大得多

并且它包含主存储器中所包含的块的子集

在这些块大小传输单元中，块在存储器中的高速缓存之中来回复制

例如，如果我们的程序请求包含在块编号 4 中的字

它要求缓存返回块 4 中包含的字

缓存在它的块的子集上搜寻这个块

它发现块 4 不存在

所以它要求主存储器发送块 4

然后存储器照做了，然后当这个块到达缓存时

缓存存储它，但也有可能需要覆盖一些现有块

同样的，如果我们的程序请求一个数据字

包含在第 10 块中的数据

缓存搜寻之后发现它没有该块

因此它请求将内存将该块复制到缓存中

这将会覆盖现有的块

如果我们的程序请求

如果我们的程序需要引用块 10 中包含的字

这时，我们说缓存「命中」，缓存就可以立即返回该块

无需经历费时长的操作，通知内存、并从内存中获取该块

现在有一类非常重要的缓存，即所谓的「高速缓存储存器」

它包含在 CPU 芯片之中

并且完全由硬件管理

它们是使用快速 SRAM 存储器实现的

处于「寄存器组」附近的缓存的实质是

是存储主存储器中经常访问的块

幸运的是，因为「局部性原则」

我们请求的大多数数据实际上都会从这个缓存内存中提供，这只需要花费几个「时钟周期」

而不是从这个缓慢的主存

高速缓存存储器完全由硬件管理

所以这里关键是，硬件逻辑得知道

如何查找缓存中的块，并确定是否包含特定块

因此，必须以非常严格且简单的方式去组织高速缓存存储器

查找逻辑可以非常简单

所有缓存存储器都按以下方式组织

你可以将缓存视为由 S=2^s 个「组」构成

每一组都包含 E=2^e 「行」

其中每一行由一个 B=2^b 字节的数据块组成

存在一个「有效位」，指示这些数据位和数据块实际上是存在的

当你第一次打开机器时，它们可能只是随机比特位

缓存中没有任何实际内容

这些位将具有值，要么为 1 要么为 0

但它们实际上并不属于数据的一部分

有效位告诉我们这些 B 字节是否实际意味着什么

然后，还有一些称为「标记位」的附加位

这将帮助我们搜寻块，我将马上向你展示

现在我们谈谈缓存大小

我们指的是块中包含的数据字节数

所以每个缓存都有 S 组

每个组都有 E 块

并且每个块有 B 个字节

所以总缓存大小 C=S*E*B

好了，这些名词确实有点难以理清，而且很容易混淆

混淆行和块以及行和组之间的不同

好的，我们将通过一些例子，希望这些能够你们帮助你们理解

让我们来看一下缓存硬件如何实现读取

当我们的程序访问时，程序会执行指令

这引用了主存中的一些字

CPU 将该地址发送到缓存

询问并要求缓存在该地址返回字

因此缓存占用该地址

对于 x86-64，这将是 64 位地址

它将地址划分为多个区域

这由缓存的组织决定

他们是由那些参数 S 组决定的

s 设置的数量是每组的行数，b 是每个数据块的大小

因此，b 个低位地址，用于确定块中的偏移量

那个字开始

接下来的 s 位被视为无符号整型

它作为组的集合的索引

记住，我们只是将这些缓存视为一个组的数组集合

设置的索引位为这个数组提供索引

剩下的所有比特

所有剩余的 t 位构成了我们称之为「标签位」的东西

这将有助于我们进行搜索

缓存逻辑采用此地址

它首先提取集合索引

并使用它作为此数组的索引来识别该组

如果这个块在集合中，抱歉，如果是数据字

如果包含此地址的数据字的块存在缓存中

它将在 set 索引表示的集合中

首先，它确定要查看的索引

然后它检查标记位，它检查该组中的所有行

要查看这些行中是否有任何匹配的标记

这是一个与标签位和地址匹配的标签

并检查有效位是否置为一

因此，如果这两个条件成立，那么组中的每个位置都有一行

至于有效位是 1，并且有匹配标记的位置

那我们称之为「命中」，我们正在寻找的块包含在这个组中

一旦我们已经确定了该块

然后缓存使用低 b 位来确定它的位置

我们感兴趣的数据在该块内

我们来看一个关于最简单方式的缓存的具体的例子

当每组只有一行时 E=1

所以 E=1 每组一行

这种缓存称为「直接映射缓存」

这里我们有 S 组，每组由一行组成

现在假设我们的程序引用了数据项

并且 CPU 感知到缓存的地址

缓存将该地址分解为这三个字段

对于此特定地址，块偏移量为四

组索引是 1 ，然后有一些标记位，我们只是用粉红色表示

因此缓存提取的组索引为 1

使用它作为组的索引

只是忽略了所有其他的组

如果我们正在寻找的块是...在缓存中它将在这个插入的第一个

然后它进行标记位和有效位的比较

并假设他们有效位和它匹配

然后它查看块偏移量为 4 的地址

并且它告诉它这 4 比特就是指令引用的内容

4 个字节开始偏移为

缓存把这视作 int 格式，将它发送回 CPU，并将其放入寄存器中

如果标签与旧行不匹配，如果标签位不匹配，则表示「未命中」

在这种情况下，缓存必须从内存中获取相应块

在行中覆盖此块

然后它就可以服务，它可以从块中取出字并将其发送回处理器

现在让我问一个问题，只是为了检查你是否跟上了进度

如果有一个未命中

并且缓存有两个向内存的请求

从内存中获取它，然后覆盖当前行中的块

是否还必须更改标记位或保持不变？

那么这一行中的标记位是否会被不同的值覆盖

还是一样吗？相同？不同？相同？不同？

现在为什么会有所不同

 - 是的，我们没有改变 -  [学生说话]  - 对不起哦 -  [学生说话]

哦，几乎可以确定它的数据不同

但只是有一个不同的地址

因为标记位而发生未命中

因为标记位不匹配，而未命中

如果有效位为假即使标记位匹配了，那么这也是未命中

那你就不会......那是......好吧

让我多说一点，让我讲一个非常简单的具体例子，关于直接映射如何工作的例子

我希望你能真正了解这是如何工作的

但我也想说明直接映射缓存的不足及其原因

为什么希望每组包含多行

这是一个非常简单的内存系统，由 16 个字节组成

一个不是很够用的 4 位地址系统

它被分解为包含 2 个字节的块

我们的缓存由 4 组组成，每组一个块

现在 4 个字节，4 位地址

因为 B=2，即 2^1 ，我们只需要 1 个块偏移位

在一个块中只有 2 个字节，所以我们要查找的字节是 0 或 1

因为我们有 4 组，我们需要设置索引位

最后剩余的位总是标记位，在这种情况下只有一个标记位

假设我们的程序开始执行指令

引用地址为 0,1,7,8 和 0 的内存

这些引用它们每次读取一个字节

我说了这是一个非常简单的系统

让我们来看看现在发生了什么

我们开始检查标记位，初始时，缓存是空的，有效位都被设置为零

缓存接收对地址为 0 的字节的请求

因此它提取组索引位，在本例中为 00

它将在第 0 组中查找

在这种情况下，因为有效位是 0，它只是一个未命中

它从内存中取出该块

这个内存就是......使用数组符号来表示内存

这就像在内存中，从偏移 0 延伸到偏移 1 的字节

标记位为 0，有效位为 1

下一个选取的地址是地址 1

这是一个命中...因为我们...包含地址 1 字节的块已经在缓存中

标签位匹配正常，很好，这是一个命中

我们得到地址 7

缓存提取组索引位，在这种情况下是 11 或 4 或 3

在第 3 组中查找，发现有效位为零，因此这是一个未命中，并且它会从内存加载数据

跨越字节 6~7

在这种情况下，标记位为 0

我们在元数据中记录了这一点

下一个引用是地址 8

8 的集合索引为 0,00

但那个目前被块 0-1 占据

我们可以发现，因为地址 8 的标签位为 1

而现有的块，地址为 0 的早期地址处的块具有 0 标记，因此这是一个未命中

所以我们必须将包含字节数 8 的块提取到内存中

我们有 8-9 字节，我们设置了新的标签位

现在下一条指令是字节 0

我们刚刚更换了，也就拥有了这个块，即在缓存中有了它，我们只是替换它

不幸的是，这是另一个未命中

我们错过它的唯一原因是，我们每组只有一行

所以我们被迫覆盖它

那块包含字节的块，当我们在块 8-9 时未命中时的块 0

你看我们的缓存中有足够的空间，我们还有两行

我们甚至都没有访问权限限制，因此我们的缓存非常大

但仅仅因为我们的缓存关联性低

以及我们呈现的访问模式的类型

我们有一个有点不必要的未命中

不好意思

[学生说话]

6，所以当我们引用 7

它实际上就是 6-7 区块中的偏移量

因为块是两个字节，它们总是以偶数倍开始

还有其他问题吗

所以这就是为什么缓存需要具有更高的关联性，更高的 E 值的原因

让我们看看......对于 E 的值大于 1 的情况

我们将它们称为 「E 路相连高速缓存」

所以这里 E=2 ，所以它是两路组相联缓存

假设我们有一个两路组相联缓存

这里我们有一系列的组，现在每组包含两行，而不是一行

并且假设我们被提供了具有以下形式的地址

我们正在寻找从区块内的偏移量 4 开始的字

在第一组内

缓存需要提取组索引

这是组 0 ，这是组 1 ，这是组 2，抛弃其他的组

现在开始并行搜索，搜索标记位，在每组的两行中搜索匹配的标签位

如果我们得到匹配的标记位和有效位

就是缓存命中

是的

[学生说话]

哦，这是一个非常好的问题，这里的确存在比较检查的硬件逻辑

因为随着关联性的增加，逻辑电路变得越来越昂贵

这就像是某种东西......就像你在做某种二叉树搜索一样

所以这实际上是限制的原因

意思是说，通常情况下，如果你把要求电路特别便宜，那么只能存在一个组

我们称之为「全相联高速缓存」，因此只有一个组

而现在任何一个块可以存在于任何地方

你放置一个块，不存在任何限制

但由于完全关联搜索的复杂性

实际情况中，它是非常罕见的。我们确实会看到全相联高速缓存，除非是在软件级别的缓存中

好的，在软件中，硬件的复杂性

而

对于具有较低关联性的惩罚，不值得硬件的复杂性

但是稍后我们研究虚拟内存时，会有一些这样的系统

在虚拟存储器系统中，DRAM 作为存储在磁盘上的数据的高速缓存

正如我们上次看到的未命中

如果你在 DRAM 上有一个缓存, 但你未命中，你必须转到磁盘

这个耗时是非常巨大的

因此，拥有比较复杂的搜索算法是值得的

特别是在虚拟存储器系统中，DRAM 实现了完全关联的高速缓存，其中来自磁盘的块可以存储于任何地方

当我们学习虚拟内存时，会更深入的了解此内容

无疑，你会在真实的系统中看到它

现今，数目在快速增加，因为特征尺寸在减少

设计人员可以负担得起更昂贵的硬件

我所知道的最大的关联性是 Intel 系统，是 16 路组相联 L3 三级缓存

其他的大多是 8 路组相联

这就是现在最先进的组数大小

一旦我们确定匹配，我们就检查组偏移位

在这种情况下，我们正在访问一个短整型，因此 4 是该区块内的偏移量

两个字节短整形，然后我们可以把数据返回给处理器

让我们做之前做过同样的模拟

但这次使用了 2 路组相联

内存系统是一样的

但现在我们有两个组，而不是一个组

抱歉，我的意思是说，我们有两套而不是四套

所以这是相同大小的缓存

但我们只是以不同的方式组织它，而不是单路组相联高速缓存，而不是直接映射缓存

包含有四行，每组一行

我们将实现一个双路组相联高速缓存，其中我们有两组，每组又有两行

所以案例总共有四行

请讲！

[学生提问]

以便以某种方式提出请求

实际上，而我并不知道具体细节

它可能......我猜...它可以要求......

这可能是一个，它总是一个 64 位，然后处理器提取当前比特位

我实际上不知道那个细节

但它要么在请求中，要么处理器解析标准大小

我们假设缓存知道返回的大小

[学生说话]

如何决定要替换哪个块？这是一个非常好的问题

有很多不同的算法

最常用的算法是「最近最少使用」策略

根据局部性原则，你希望将缓存中的块将被尽可能多次的使用

逆着局部性原则思路来思考，如果一个块长时间不被引用，

在不久的将来，它也不太可能会被引用

这就是一种算法

你只是跟踪，我没有说那里需要额外的位

类似于在排序中，保持虚拟时间戳

但这只是你做这件事的常规方式

只是尽量保持最常访问的块

[学生说话]

好问题，是什么决定了块的大小

这是由内存系统的设计决定的

这是内存系统的固定参数

因此，当 Intel 设计师决定将缓存存储器放在他们的处理器上时

他们决定了块大小为 64 字节

不好意思

因此，先解决块大小

然后决定你所期望的缓存的大小

然后你再确定关联性

一旦确定了关联性，就可以知道缓存有多大

然后确定组的数量

基本上所有这些

行数的数量和容量大小

每组的行数是固定的高级设计参数

缓存的大小是高级设计参数

由此可以推断组的数量

是的

[学生说话]

那是怎么如何实现的......这就是替代策略

如何在一组中有多行时，确定哪些将被覆盖

这是之前的问题，也许我应该重复一遍

你应该尝试选择最近最少使用的行

所以最近没有访问过的行

很适合替换，因为

由于这种逆向局部性原理的正确性

它们最近没有被引用，它们将来不会被引用的可能性也很大

再一次

哦，是的，这里还有一些东西我还没提到

当你替换组中的一行时

如果该数据已更改，则必须将其写回内存

这是我没讲的地方

请讲

[学生说话]

啊，所以是的，所以这真是一个非常棘手的参数问题

它是一个高级系统参数，它持续多年

你想要通过块以利用空间局部性的想法

想一想，如果你缓存未命中，你是否会遇到麻烦

而且你将会遇到麻烦，只能去内存中获取一些数据

你希望通过获取多个字节，来分摊获取该数据的成本

这是块的本意

因为特别是在空间局部性的原则上

如果你引用块内的字

你可能会引用附近的字，这也是一个结尾

块的整个目的就是利用空间局部性

如果你的块太小，那么你就不会摊销

你没有获得相同的摊销，你可能得到一个

你把块带进来

有一个引用，你得到一个未命中，你带来了块并放置于此

附近有另一个引用，因为内存中已存在的块，你会命中缓存

但接下来的引用是在不同的块中

因为你的块实在太小

所以你想要使得块尽可能大

但不至于减慢系统速度

因为如果你将块大小设置得过大，则需要花费太长时间才能放置该块

再加上你的块占用缓存内存中的位

没有其他块的空间了

这是一个非常棘手的设计问题

如果我们正在做一个计算机体系结构课程，那么我们就会深入研究

你将会学习架构师如何做出这些设计决策

但总的来说，这是一种平衡行为

还有其他问题吗？

[学生说话]

哦，问题是每次都有缓存未命中

你是否必须选择受害者行并覆盖它

是的，我不知道任何不这样做的缓存

现在我们将看到我们何时看待 rights

我们会看到有一个选项，我们是否只是立即查看

但是 rights 确实会出现问题

如果你等待几张幻灯片，我们就会讲到这

还有其他问题吗

好的，现在让我们来看看这个二路组相联缓存

有一个块偏移位

我们只有两个组，所以我们只需要一个组索引

然后标记剩下的两个比特位

让我们进入我们的跟踪，地址零有一个组，在这里设置为零，这是一个未命中

我们把它加载到内存中

参考地址 1

这是设置为 0 ，这是一个命中，因为该字节在一个块中

对 7 的引用是在第一组中的未命中，因此我们加载它

而我们只是随意挑选这两个中的一个

因为缓存是空的

下一个引用是地址为零的地址

这是直接映射缓存和这个双路组相联缓存之间的区别

当我们引用地址 8 时

该块以及相邻的块也必须放进组 0

因为这个 0 组索引位

但是我们现在已经有了空间，因为我们可以设置两个组而不是一个组

如果我们有一个可用的空槽，那么当我们将其加载好时

我们将它放在那里，我们不会覆盖任何正确的，所以如果可能的话总是试图覆盖空行

现在我们已经进入了这个组......我们有 0-1 区块和 8-9 区块

所以当我们得到我们的地址 0 的引用时

而在之前，我们在直接映射缓存中发生了冲突未命中

现在我们可以满足那个请求

它在内存中命中，缓存可以从缓存中满足它，而不是去内存取回数据

明白了吗

好的，写又是如何呢？

有多个数据副本

我们正在进行子设置，因为我们在层次结构中向上移动，我们在缓存中创建数据的子集

那么我们对当前在缓存中的块内的数据字进行写操作

我们有两个选择

我们可以立即将该块写入内存

我们有一个这么大的块，我们正在更新它的一小部分

我们可以进行更新，然后立即将其刷新到内存中

因此，内存始终保持着缓存的镜像

好吧，但这是耗费高的写方式

意思是，你知道内存访问是非常费时的

另一个选择就是所谓的「写回」

在这种情况下我们写入缓存中的块

我们不会将其刷新到内存中

直到我们选择的那条特定的组作为被替换者，才会被覆盖

只有这样，我们只是推迟写入的时间

尽可能的直到最后一分钟才写入内存

我们将其推迟到缓存覆盖该数据块之前

是的，这就叫「写回」

对于写回，你需要在行中加一些额外的位来指示是否写入了这些块

因此，算法就是：当缓存识别出一个特定行将覆盖时

它检查该行上的「修改位」，如果已设置，则将该数据写回磁盘

如果数据没有写入，那么没有必要将其写回来

因为它与磁盘上块的副本具有相同的值

这里有一个写操作，如果我们有一个正确的缓存未命中，看看会发生什么

我们正在对内存进行一个写操作

我们写的字，不包含在缓存中的任何块中

我们有两个选项，我们可以叫做「写分配」。如果有一个缓存未命中，那么就能处理了

如果缓存命中了，我们可以做一些对称的事情

一个新行可能会覆盖现有行

然后写入，以便我们可以创建该缓存，进入该缓存行

从内存中获取它，然后执行写操作

这对于那时的读取来说是对称的

因此每一次写未命中，那个块将会在缓存中

如果我们进行后续读操作，就会有缓存命中

这就是要这样做的原因

另一种选择就是

「非写分配」，不要分配新行，只是将数据直接写入内存

你真的不需要理解这两件事之间的区别

不同的缓存使用不同的策略

对于你自己的心中好的模型，就是假设写回写分配

假设我们不会将数据复制到磁盘

如果发生了缓存命中，我们直到最后时刻才将其写回磁盘

每次有「写未命中」，都会在缓存中创建一个新条目

我觉得这是最简单的模型

这是一个合理的模型，无论特定的缓存实现如何，你都可以使用它

到目前为止，我们假设在一个真实的系统中，只有一个缓存

但在实际系统中，会存在多个缓存

现代核心 i7 拥有来自英特尔的良好架构

包含多个处理器核心

所以 4 是类似桌面系统的典型数字

8~12 是服务器类系统的典型代表

这些处理器内核可以各自并行执行它们自己的独立指令流

并且每个处理器内核可以包含通用寄存器，其在高速缓存层次结构中为 0 级

然后是两种不同的 L1 缓存

数据缓存「L1 d-cache」

而「i-cache」是指令缓存

这些是相当小的 32k 字节，它们是八路组关联的

并且可以在极少的时钟周期内访问它们

层次结构的下一级是「L2 缓存」

这仍然是相当小的 256k 字节，相同的关联性

它的访问时间稍长一点

在 L2 缓存包含数据和指令的意义上，它是统一的

这一切都在芯片的单核心内

然后在芯片上，但在所有内核外部，并由所有内核共享的

是「L3 统一缓存」，其大小 8 兆字节和 16 路组相联

访问时间大约为 40 到 75 个周期

如果在 L1 中出现未命中，则 L1 感知到，然后尝试向 L2 发送请求以尝试在 L2 中查找数据

由于 L2 稍微大一点，又或许数据还没有从 L2 中刷新

如果 L2 无法找到它，它会向 L3 发送请求，以查看它们是否可以在 L3 中找到数据

如果 L3 中也找不到它，那么它就会放弃，它会从芯片到内存中消失

请说你的问题

是的，是内存，这是由 DRAM 芯片构成的 DRAM

它是独立的，存在主板上的一组独立芯片中

通过那些 I/O 桥连接

我们上次谈到了各种总线

对于所有这些不同的缓存，所有不同的块大小为 64 字节

现在有很多不同的方法来考虑缓存的性能

最常见的方法是使用称为「未命中率」的指标

这是关于未命中的参考文献的一部分

这是 1 的命中率

对于正常工作的缓存来说，典型的未命中率必须非常低

幸运的是，由于局部性原则，这些未命中率很低

另一个指标是「命中时间」

如果我们确实在缓存中有一个命中，它实际需要多长时间...

用你所知道的查找排序，确定有一个命中，然后返回值

对于 L1 和在 intel 系统中，这会花费 4 个时钟周期，L2 为 10 个时钟周期

还会有额外的费用

你总是要付出命中时间，你应该在这部分尽力做到最好

但是，如果你有一个未命中，那么你需要花费命中时间

因为你必须进行搜索，最终你必须将该字返回给请求者

你会有这个额外的损失

你必须去哪个内存准备好获取数据

这样的未命中所带来的惩罚，这就是所谓的「未命中处罚」

对于主存储器来说，是大约数百个时钟周期

但在层次结构的其他层面，它可能就会特别耗时

因此，如果你在主内存中有缓存

这是存储在磁盘上的缓存块，未命中处罚将会十分严重

如果你想一想，这里有意思的是

这些系统的性能对未命中率非常敏感，比你想象的要灵敏得多

事实上，99％的命中率是97％命中率的两倍

是

[学生说话]

是的，他们命中了，问题是命中时间是否包括访问标记位的时间

命中时间是搜索所需的时间

确定该项是否在缓存中，然后将其返回

[学生说话]

是的，未命中处罚就是它从内存取回数据所花的时间

它是你所知道的所有延迟的之和

内存响应请求所花费的时间

数据通过总线返回缓存所需的时间

未命中的时间将是命中时间加上明确的未命中处罚

假设有一个时钟周期的命中时间，和100个周期的未命中处罚，这实际上是合理的数字

如果你有 97％ 的命中率，

平均访问时间是命中时间加上未命中处罚乘以百分系数

所以平均访问时间是四个周期

但如果我们只将命中率提高 2％

平均访问时间就会减少了 50％，减少了两倍

为什么这个东西很重要，为什么要关心它呢？

缓存就像我们所看到的那样，都是自动执行的，是由硬件构建的

不存在那种所谓的可见指令集

去允许你操作缓存和组装机器代码程序

这一切都在硬件中自动在幕后执行

如果你知道缓存的存在

而且你对它们的工作方式有了一个大概的了解

然后你就可以编写缓存友好的代码

从某种意义上说，你的代码会比不缓存友好的代码具有更高的未命中率

关键在于......你应该专注于使得更常用的部分更加快一点

不要把时间花在那些代码不能很快执行的代码上

所以看看最常见的函数


然后在这些函数中查看这些函数的内部循环

因为它是执行最多的内循环

所以你可以做一个初步近似，忽略一些东西

如果你有嵌套循环，你可以忽略外循环中发生的事情

然后只关注内循环中的代码

现在你想要做的是尽量减少内循环中的未命中

如此重复引用变量是好的

特别是对于那些局部变量来说

请记住，如果你声明一个局部变量

编译器可能将它放在寄存器中

如果你正在引用全局变量

编译器不知道发生了什么

因此它无法将该变量的引用放入寄存器中

如此重复引用存储在堆栈中的局部变量是好的

因为那些将变成寄存器访问

你永远不会去内存取回数据

逐元素的访问数组是有利的

由于块的存在，它们是有利的

所以如果你知道的话，唯一的方法就是知道那个步长为一引用的好处

高速缓存的块大小为 64 比特

所以逐步引用相对于步长为 2 的引用，只会有一半的未命中率

因为如果你正在做步长为 1 的引用，则引用对数据字的第一次引用，将会未命中

但对其随后的元素的引用将会命中缓存

如果你在做一个步长为 1 的引用，那么将会命中将要访问的块中其余的每个字

如果你的驱动器，如果你在做步长为 2 的引用，你只会命中剩下的字

对，所以你会得到一半的命中率，也就是加倍的未命中率

所以

基本上我想对你们说的是，我们对缓存的理解

让我们来量化上一次介绍的局部性概念

上一次看到的时候，我们说过如果它正在做步长为 1 的引用，那是缓存友好的

如果我们一遍又一遍地访问同一个变量，那也是缓存友好的

如果我们了解了缓存，我们可以根据未命中率对其进行量化

让我们继续完成课程的其余部分

我们将研究缓存对代码的性能影响

为什么你需要知道这些事情

以及他们会造成的影响

有一个非常有趣的函数

实际上绘制在教科书的封面上

我们称之为「存储器山」

我从 90 年代卡内基梅隆大学的名叫汤姆史翠克的研究生那里了解到这个，他提出了这个概念，

存储器山，它描绘了一种称为「吞吐量」或「读带宽」的衡量标准

也就是从内存中读取的字节数

如果你有一个循环，而你正在扫描一个数组

一个双精度 double 类型的数组

而且你正在逐个从数组中读取这些元素

读吞吐量是执行该任务的每秒兆字节数

在存储器山图上表示为读取吞吐量

作为该循环中的时间和空间局部性的函数

从某种意义上说，它考虑程序中的各种局部性选项或特征

将该存储系统的性能在该范围内作为二维函数绘制出来

从某些角度来说，存储器山就像指纹一样

每种系统都有自己独特的记忆山

我们可以通过编写一个简单的程序来衡量

这里是要构建记忆山

我们编写了一个名为 test 的程序

哦

出于某种原因，事实并非如此

好的，没错

当我们建立一座记忆山

给出了一个由双字组成的向量

然后我们编写一个循环来读取在这种情况下读取一些字

嗯

开始了

它读取 elem 元素数量

我们将通过步长 stride 获取每一个双字

如果步长为 1

我知道那有点多余了

如果步长为 1

然后我们将循环遍历一遍

直到我们读完了 elem 个元素

然后我们再次这样做，这会加热缓存

我们再做一次同样的事情

如果我们以两个步长这样做

我们会读到这个字 0 或字 2 字 4 等等

那么我们所做的一切只是因为步长的不同取值范围

和各种大小

我们正在扫描这个数组，只记录读取所需的时间

然后我们将其转换为每秒兆字节

而且为了突出我想告诉你们的，而这是我们不需要知道的，所以不打算详细讨论这个问题

这实际上就是我如何制作出书本的封面

为了利用 intel 处理器内部的并行性

就像你上周学到的那样，有许多并行的功能单元

为了利用那些，我做了 4x4 循环展开

所以我实际上并行进行了四次扫描

但总的大概就是我在这里向你们展示的内容

这个 4x4 循环展开只是一个优化

我想向你展示它，因为它实际上是完全相同的原则

你上周了解了布莱恩特教授谈到的代码优化

我们所做的是，我们称这个测试函数具有不同大小的 elems 和 stride

我们评测性能，得到了这幅美丽的图

这个美丽的函数，对我来说它是美丽的，我不知道它对你们来说是否依然美丽

所以在 z 轴

在z轴上绘制读取吞吐量，以兆字节/秒为单位

范围从每秒 2000 兆字节到每秒 16,000 兆字节

这个轴表示的是步长

所以从步幅 1 到步伐 12

而这个轴是......当我们增加步幅时，我们在减少空间局部性

好的

这个轴是 size 轴，所以我们认为大约是从 16K 到 128M

这是我们每次传递时要读取的元素总数量

正如我们增加 size 一样

因为字，我们减少时间局部性的影响

随着我们增加 size ，我们的层次结构中的可以容纳数据的缓存越来越少，

所以这样我们就可以在这个方向上减少空间局部性

并且时间局部性在这个方向上减少

所以作为程序员你应该想办法在这里，做你认为该做的

良好的空间局部性，良好的时间局部性

因为你可以达到每秒 14GB 的速度，来衡量一致的吞吐量

你不想在这里

在你读取内存时，每秒只有大约 100 MB

从内存中读取数据

和从缓存的某些部分读取它,这两者之间的区别是巨大的，极大的

你们在座的是 213 课程的学生，你们会处于这个存储山的上方

没有来 213 上课的学生，他们会在这底下

有几个同学写信回来告诉我

告诉我，他们离开 CMU 之后在实习和工作中所了解的经历

他们在那里被分配负责一些代码

他们意识到了局部性问题，他们得到了处于上方的缓存友好的代码

这张所谓的存储器山，有各种有趣的特征

首先，我称之为「时间局部性的山坡」

如果你认为这就像一座山，这些山脊会看到这些山脊线

你看到这条山脊线，你看到这条山脊线

而这里是另一条山脊线，然后这里是另一条山脊线

这些对应于层次结构中的不同级别

所以这条顶部山脊线就是你从 L1 直接读取的地方

它应该是完全平坦的

这是如此之快，以至于我们正在获得性能抖动

这里的一点点下降，是一个多余的测量时间函数

它本应该是平的，一直到这里的墙

然后在这里这条山脊线是我们访问 L2 的地方

这是我们访问 L3 的地方

这是我们主要通过内存访问的内容

所以你有这些时间局部性的山坡

然后你有这些空间局部性减少的斜率

所以你看到这里的斜坡

正如我们正在从斜坡顶部向下移动到底部

我们正在减少我们的空间局部性，因此我们带来的这些块的增益会减少

你可以看到我们从额外的消耗中获得的收益越来越少

我们需要这些块的导入

一旦步长达到块大小

每个引用都会遇到不同的块

然后它变得平坦，然后你不会从空间局部性获得增益

这里的斜率是我们从 L3 读取的地方

它变得平坦，它们总是在达到块尺寸时变平，就是当 stride 等于双字大小时

步长为 8 就是 64 字节

一旦你超过8的步伐，你就不再有增益了

你每次都在不同的块

有趣的是，这个让我困惑了一段时间

你可能想知道我们在这里如何增加 size

就像增加 size 一样

我们从缓存层次结构中较低的缓存中执行大多数引用

除非我们在使用步长为 1 的引用

你可以一直到最后

就在它超过 L3 的大小之前

它很平坦

并且它以 L2 速率运行

这里是 L1 率，然后它下降，最后它以恒定的 L2 速率运行

直到数据不再适合 L3

所以我认为这里起作用的是硬件

L2 高速缓存硬件正在识别，或者可能是 L1

但是缓存系统中的硬件逻辑，正在识别步长为 1 的引用

因为它看到了所有的地址

它识别出为步长为 1 的模式

然后它积极地从 L3 预存取到 L2

那些提前取出的东西

它说我已经连续五次引用步长为 1

需要去抓取一大堆块，然后加载它们

因为根据空间局部性原则

这些块将在不久的将会被引用

所以这真的很整洁，这仅仅发生在过去的几年里

英特尔工程师总是在努力改善

也许到我们下一版本的存储器山的时候

那些系统将识别步长2

但从这些数据来看，它似乎只是认识到了步长为 1

我们可以改善我们程序的空间和时间局部性

以几种不同的方式，改善空间局部性的一种方法是「重新排列循环」

我们将使用矩阵乘法作为例子

这是代码中的简单矩阵乘法

我们把 a 乘以 b 并加上它

我们正在取出 c[i][j] 中的内容

然后我们将 a 的第 i 行和 b 的第 j 行 j 的内积相加

那么我们将通过这个矩阵 c 中的每个 i，j

我们正在计算内积，然后创造这个总和

我们实际上可以证明有很多不同的方法来进行矩阵乘法运算

我们可以置换这些循环

置换成六种不同的可能排列中的任何一种

所以这是一个排列，其中 i 跟着 j，k

其他五种可能性同样也是可行的

实际上，我们可以分析那些不同的排列

并预测哪一个会有最佳表现

我们要做的就是看看内循环

看看内循环的访问模式

它位于数组 c，a 和 b 的访问模式中

让我们来看看 i，j，k 实现

我们始终专注于内循环

如果你注意到这个内部循环正在对列 a 进行行方式访问

并且列优先的访问，不对，行优先访问数组 a

并且列 b 地访问

顺便说一下 b 的列，我们并不关心 c

因为它不在内循环中，所以只需忽略它

假设在这种情况下

我们可以在一个块中保存这些整数元素

因此，具有良好空间局部性的行式访问发生缓存未命中，每四次访问一次未命中

第一个引用将错过，然后接下来的三个将被命中

在那之后的下一个引用将命中到一个新的块

四分之一的引用会未命中

但由于 b 的访问模式是列式的，因此每次对 b 的引用都会丢失

每次循环迭代的平均未命中数是 1.25

好吧，j，i，k 版本是完全相同的模式

K，i，j 在这里有点不同

我们正在对 b 进行逐行访问

并且明智地访问 c，这样才对

现在我们在 b 和 c 上都进行了单元素依次访问

对 a 的引用是在循环之外，所以我们不关心它

b 和 c 都是四分之一的未命中率

每次循环迭代的总平均未命中数将为 0.5

这是非常好的，i，k，j 具有相同的相似行为

现在 j，k，i 恰恰相反

j，k，i 按列进行访问 a

对于 c 的列式访问权限，我们知道这是一个很难找到的东西

而且我们定性很好，你知道它很糟糕，我们可以计算出它会错过每循环迭代一次

这样每次迭代总共会有两次失误

和 k，j，i 有相同的坏模式

如果我们看看所有这些排列

你可以看到 i，j，k 和 j，i，k 平均有 1.25 次未命中

k，i，j 有 0.5 个未命中，j，k，i 有 2 个未命中

很明显，看起来 k，i，j 及其兄弟是最好的选择

唯一的区别是 k，i，j 有这个额外的储存

因此，可能存在一个问题，即创造的是减慢速度

在任何类型的存储系统权利系统中都证明了这一点

处理读操作更容易

你能想一想为什么会这样吗？

写操作比读取操作更为灵活

是的

这就是你可以做的选择，你可以写回来推迟你可以推迟写

直到你实际使用的值

但是当你读到一元素时，你就会陷入困境

在获得该数据之前，你无法做任何事情

事实证明，写操作并不是， 真的这个额外的存储并没有真正影响到我们

当我们在现代系统上测量这些时

你可以看到 k，i，j 具有最少的未命中数

你有没有看到我们，我们在这里绘制的是每个循环迭代的周期

所以每次迭代都需要大约一个周期，这非常好

这种 i，j，k 模式是中间体 1.2 的一种未命中

这种情况介于两者之间，每次迭代有两次未命中的 j，k，i 是最差的

有趣的是我们实际上可以通过做一些分析

可以预测这个图形的样子

在课程的最后十分钟

我们将研究如何改善时间局部性

当我们重新安排我们的循环时

在矩阵乘法中，我们正在做的是改善我们的空间局部性

但我们并没有真正做任何改善时间局部性的事情

要改善时间局部性，你必须使用称为「阻塞」的技术

这一点很重要，因为你需要在缓存实验室中完成

但它也是一种非常通用的技术

任何时候你需要，任何时候你遇到时间局部问题

可以，然后呢

c = (double *) calloc(sizeof(double), n*n);

/* Multiply n x n matrices a and b  */
void mmm(double *a, double *b, double *c, int n) {
    int i, j, k;
    for (i = 0; i < n; i++)
	for (j = 0; j < n; j++)
             for (k = 0; k < n; k++)
	         c[i*n + j] += a[i*n + k] * b[k*n + j];
}


我们不打算详细介绍这段代码，但是我重写了矩阵乘法

它运行时你知道一个二维矩阵，可以把它想象成一个连续的字节数组

我只是重写了这段代码来操作一个连续的数组，一维数组

然后我在这里使用显式索引

这里在 c[i * n + j] 这是 n 矩阵

我正在做的是......

然后我将转到该行的j列，然后访问该元素

让我们......但它和以前一样

因此，让我们看一下这个未命中率，这是一个原始的无阻塞矩阵相乘

我们正在做计算 c[0][0]

我们通过采用第 0 行和第 0 列的内积来做到这一点

如果你看一下我们假设缓存块有 8 个 double

并且矩阵元素是双精度浮点数，那么我们每八次将会有个未命中

在第一次迭代中

我们将错过这些事情的第一次迭代

因为我们在八分之一的时间里都缺席了

我们每八个引用丢失一个块

对于第一次迭代的每一次，我们将每八次未命中一次

因为每个块的每个元素都有 n，不对

哦，所以这是块数和未命中数，然后我们有n个元素

因此，第一次迭代的未命中总数为 9n/8 次未命中

第二次迭代将有相同数量的未命中

因为我们对这个数组大小的假设

所以这些行太大了，不适合缓存

所以我们永远不会得到任何我们没有得到任何时间局部性

总失误次数是我们正在更新的元素数量的 9n/8 倍，即 n 平方

所以我们的总失误是 9n/8*n^3

c = (double *) calloc(sizeof(double), n*n);

/* Multiply n x n matrices a and b  */
void mmm(double *a, double *b, double *c, int n) {
    int i, j, k;
    for (i = 0; i < n; i+=B)
	for (j = 0; j < n; j+=B)
             for (k = 0; k < n; k+=B)
		 /* B x B mini matrix multiplications */
                  for (i1 = i; i1 < i+B; i++)
                      for (j1 = j; j1 < j+B; j++)
                          for (k1 = k; k1 < k+B; k++)
	                      c[i1*n+j1] += a[i1*n + k1]*b[k1*n + j1];
}

现在让我们重写代码以使用阻塞等等

你可以稍后查看此代码

但是以图形方式看待它会简单得多

我们正在做的不是一次更新一个元素

通过 b 子块更新子块 a b

我们这样做完全类似于原始情况，其中 b = 1

这个 b*b 子块和 c 是通过取子块的内积来计算的

a 中的一组子块中的一组子块中的 b

对于每一个我们正在做一点迷你矩阵乘法

所以我们将这个子块占用了这个子块

加上 b 的第二个子块的第二个子块

加上第三个子块，一次是b的第三个子块，依此类推

我们正在做同样的内部乘积操作

但是我们用这些小小的矩阵来代替标量

让我们来看看当我们这样做时未命中率会发生什么

在任何行或列中都有 n 个 b 块

并且因为每个块 b*b 中有 b 个平方项

每个区块都有 B^2/8 未命中

然后因为每个矩阵中有超过 b 个块，并且有两个矩阵

第一次迭代有 2n/B*B^2/8 未命中

所以这可能是一个 nB/4

并且第二次迭代具有相同的未命中率

未命中的总数是每次迭代的未命中数

计算我们正在更新的 C 中元素的数量

是 (n/B)^2

这样一切都有效，它仍然在 n^3*(1/4B)

在我们的第一个没有阻塞的情况下，虽然未命中的数量是渐近相同的

但是有这个很好的，恒定因素的这个巨大差异，所以没有阻止它是 9/8

为了阻止它的 1/4b 我们现在我们可以把它降低

通过增加块大小，这给了我们一些控制

但是我们仍然有......我们无法让块块太大，因为我们需要适合三个块

在任何一个时间点的缓存中

这是一个戏剧性的差异吧

其原因在于，通过阻止我们就是在利用

一旦我们将一个块加载到内存中，我们就会一遍又一遍地重复使用它

所以我们正在利用更多的时间局部性

矩阵乘法将这种情况纳入这个隐含的局部性

因为计算是 n 阶的，但是数据的大小是 n 的平方

是的，所以我们必须重用一些数据项

我们的标量方法的问题是，我们在重用它们时它们不在缓存中

好

所以我想使你了解的重点是

高速缓存存储器虽然它们是一种内置的自动硬件存储设备

你无法控制它们

如果你了解它们，你可以利用你的知识

并利用它们并使你的代码运行得更快

你这样做的方式就像我说的那样专注于内循环

是尝试做一个跨步的访问

并尝试以最大化空间局部性

并尝试通过重用局部变量来最大化时间局部性

然后可以将其放入寄存器中

如果你还没有完成 attack-lab，祝你顺利

不要忘记本周末开始 cache-lab